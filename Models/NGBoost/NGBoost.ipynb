{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4753a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ngboost import NGBRegressor\n",
    "from ngboost.distns import Normal\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3e43b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Timestamp', 'Service', 'CPU Request', 'Memory Request', 'CPU Limit',\n",
      "       'Memory Limit', 'Latency', 'CPU Usage', 'Memory Usage'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Paths to service 1 datasets\n",
    "cpu_path_s1 = \"../../results/prometheus_data/service1_cpu_limit_reduction.csv\"\n",
    "memory_path_s1 = \"../../results/prometheus_data/new datasets/service1_memory_limit_reduction.csv\"\n",
    "both_path_s1 = \"../../results/prometheus_data/service1_both_limits_reduction.csv\"\n",
    "\n",
    "# Import datasets\n",
    "df_cpu_s1 = pd.read_csv(cpu_path_s1)\n",
    "df_memory_s1 = pd.read_csv(memory_path_s1)\n",
    "df_both_s1 = pd.read_csv(both_path_s1)\n",
    "\n",
    "df_all_s1 = pd.concat([df_cpu_s1, df_memory_s1, df_both_s1], ignore_index=True)\n",
    "print(df_all_s1.columns)\n",
    "\n",
    "# Paths to service 2 datasets\n",
    "cpu_path_s2 = \"../../results/prometheus_data/service2_cpu_limit_reduction.csv\"\n",
    "memory_path_s2 = \"../../results/prometheus_data/service2_memory_limit_reduction.csv\"\n",
    "both_path_s2 = \"../../results/prometheus_data/service2_both_limit_reduction.csv\"\n",
    "\n",
    "# Import datasets\n",
    "df_cpu_s2 = pd.read_csv(cpu_path_s2)\n",
    "df_memory_s2 = pd.read_csv(memory_path_s2)\n",
    "df_both_s2 = pd.read_csv(both_path_s2)\n",
    "\n",
    "# Combine all three DataFrames\n",
    "df_all_s2 = pd.concat([df_cpu_s2, df_memory_s2, df_both_s2], ignore_index=True)\n",
    "\n",
    "# Paths to datasets\n",
    "cpu_path_hg = \"../../results/prometheus_data/hashgen_cpu_limit_reduction.csv\"\n",
    "memory_path_hg = \"../../results/prometheus_data/hashgen_memory_limit_reduction.csv\"\n",
    "both_path_hg = \"../../results/prometheus_data/hashgen_both_limit_reduction.csv\"\n",
    "\n",
    "# Import datasets\n",
    "df_cpu_hg = pd.read_csv(cpu_path_hg)\n",
    "df_memory_hg = pd.read_csv(memory_path_hg)\n",
    "df_both_hg = pd.read_csv(both_path_hg)\n",
    "\n",
    "# Combine all three DataFrames\n",
    "df_all_hg = pd.concat([df_cpu_hg, df_memory_hg, df_both_hg], ignore_index=True)\n",
    "\n",
    "# Paths to datasets\n",
    "cpu_path_rp = \"../../results/prometheus_data/ranspw_cpu_limit_reduction.csv\"\n",
    "memory_path_rp = \"../../results/prometheus_data/randpw_memory_limit_reduction.csv\"\n",
    "both_path_rp = \"../../results/prometheus_data/randpw_both_limits_reduction.csv\"\n",
    "\n",
    "# Import datasets\n",
    "df_cpu_rp = pd.read_csv(cpu_path_rp)\n",
    "df_memory_rp = pd.read_csv(memory_path_rp)\n",
    "df_both_rp = pd.read_csv(both_path_rp)\n",
    "\n",
    "# Combine all three DataFrames\n",
    "df_all_rp = pd.concat([df_cpu_rp, df_memory_rp, df_both_rp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99f2c2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"Service 1\": df_all_s1,\n",
    "    \"Service 2\": df_all_s2,\n",
    "    \"HashGen\": df_all_hg,\n",
    "    \"RandPw\": df_all_rp,\n",
    "}\n",
    "\n",
    "test_sizes = [0.3, 0.2, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b23c71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ngboost_model(df, feature_col, test_size=0.2, plot=True):\n",
    "    df = df.sort_values(\"Timestamp\")\n",
    "    df = df.dropna()  # or use df.fillna(method='ffill') / SimpleImputer\n",
    "\n",
    "    df = df[[feature_col, \"CPU Request\", \"Memory Request\", \"CPU Limit\", \"Memory Limit\", \"Latency\"]]\n",
    "\n",
    "    features = [\"CPU Request\", \"Memory Request\", \"CPU Limit\", \"Memory Limit\", \"Latency\"]\n",
    "    target = feature_col\n",
    "\n",
    "    if \"Memory\" in feature_col:\n",
    "        df[feature_col] = df[feature_col] / (1024 * 1024)\n",
    "\n",
    "    # Scale features\n",
    "    feature_scaler = MinMaxScaler()\n",
    "    X_scaled = feature_scaler.fit_transform(df[features])\n",
    "\n",
    "    # Scale target\n",
    "    target_scaler = MinMaxScaler()\n",
    "    y_scaled = target_scaler.fit_transform(df[[target]]).ravel()\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=test_size, shuffle=False)\n",
    "\n",
    "    model = NGBRegressor(Dist=Normal, verbose=False)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "\n",
    "    # Inverse transform predictions\n",
    "    pred_train_inv = target_scaler.inverse_transform(pred_train.reshape(-1, 1)).ravel()\n",
    "    y_train_inv = target_scaler.inverse_transform(y_train.reshape(-1, 1)).ravel()\n",
    "    pred_test_inv = target_scaler.inverse_transform(pred_test.reshape(-1, 1)).ravel()\n",
    "    y_test_inv = target_scaler.inverse_transform(y_test.reshape(-1, 1)).ravel()\n",
    "\n",
    "    # Evaluation\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train_inv, pred_train_inv))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test_inv, pred_test_inv))\n",
    "    train_r2 = r2_score(y_train_inv, pred_train_inv)\n",
    "    test_r2 = r2_score(y_test_inv, pred_test_inv)\n",
    "\n",
    "    print(f\"{feature_col} - Train RMSE: {train_rmse:.4f}, R²: {train_r2:.4f}\")\n",
    "    print(f\"{feature_col} - Test  RMSE: {test_rmse:.4f}, R²: {test_r2:.4f}\")\n",
    "\n",
    "    # if plot:\n",
    "    #     plt.figure(figsize=(10, 4))\n",
    "    #     plt.plot(y_test_inv, label=\"Actual\")\n",
    "    #     plt.plot(pred_test_inv, label=\"Predicted\")\n",
    "    #     plt.title(f\"{feature_col} Prediction (NGBoost)\")\n",
    "    #     plt.legend()\n",
    "    #     plt.show()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ce8b7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training NGBoost for Service 1 - CPU Usage with test size 0.3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "check_X_y() got an unexpected keyword argument 'ensure_all_finite'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_size \u001b[38;5;129;01min\u001b[39;00m test_sizes:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining NGBoost for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - CPU Usage with test size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     model_cpu \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ngboost_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCPU Usage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining NGBoost for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Memory Usage with test size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m     model_mem \u001b[38;5;241m=\u001b[39m train_ngboost_model(df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMemory Usage\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_size)\n",
      "Cell \u001b[1;32mIn[9], line 25\u001b[0m, in \u001b[0;36mtrain_ngboost_model\u001b[1;34m(df, feature_col, test_size, plot)\u001b[0m\n\u001b[0;32m     22\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_scaled, y_scaled, test_size\u001b[38;5;241m=\u001b[39mtest_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     24\u001b[0m model \u001b[38;5;241m=\u001b[39m NGBRegressor(Dist\u001b[38;5;241m=\u001b[39mNormal, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 25\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Predictions\u001b[39;00m\n\u001b[0;32m     28\u001b[0m pred_train \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\ngboost\\ngboost.py:258\u001b[0m, in \u001b[0;36mNGBoost.fit\u001b[1;34m(self, X, Y, X_val, Y_val, sample_weight, val_sample_weight, train_loss_monitor, val_loss_monitor, early_stopping_rounds)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscalings \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol_idxs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loss_monitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loss_monitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loss_monitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loss_monitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\ngboost\\ngboost.py:384\u001b[0m, in \u001b[0;36mNGBoost.partial_fit\u001b[1;34m(self, X, Y, X_val, Y_val, sample_weight, val_sample_weight, train_loss_monitor, val_loss_monitor, early_stopping_rounds)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 384\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    395\u001b[0m loss_list \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mTypeError\u001b[0m: check_X_y() got an unexpected keyword argument 'ensure_all_finite'"
     ]
    }
   ],
   "source": [
    "for name, df in configs.items():\n",
    "    for test_size in test_sizes:\n",
    "        print(f\"Training NGBoost for {name} - CPU Usage with test size {test_size}\")\n",
    "        model_cpu = train_ngboost_model(df, \"CPU Usage\", test_size)\n",
    "\n",
    "        print(f\"Training NGBoost for {name} - Memory Usage with test size {test_size}\")\n",
    "        model_mem = train_ngboost_model(df, \"Memory Usage\", test_size)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec25d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ngboost_with_gridsearch(df, feature_col, test_size=0.2, plot=True):\n",
    "    df = df.sort_values(\"Timestamp\")\n",
    "    df = df[[feature_col, \"CPU Request\", \"Memory Request\", \"CPU Limit\", \"Memory Limit\", \"Latency\"]].dropna()\n",
    "\n",
    "    features = [\"CPU Request\", \"Memory Request\", \"CPU Limit\", \"Memory Limit\", \"Latency\"]\n",
    "    target = feature_col\n",
    "\n",
    "    if \"Memory\" in feature_col:\n",
    "        df[feature_col] = df[feature_col] / (1024 * 1024)\n",
    "\n",
    "    # Scale features\n",
    "    feature_scaler = MinMaxScaler()\n",
    "    X_scaled = feature_scaler.fit_transform(df[features])\n",
    "\n",
    "    # Scale target\n",
    "    target_scaler = MinMaxScaler()\n",
    "    y_scaled = target_scaler.fit_transform(df[[target]]).ravel()\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=test_size, shuffle=False)\n",
    "\n",
    "    # Grid search setup\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 300],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'minibatch_frac': [1.0, 0.5],\n",
    "    }\n",
    "\n",
    "    base_model = NGBRegressor(Dist=Normal, verbose=False)\n",
    "    grid_search = GridSearchCV(base_model, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Predictions\n",
    "    pred_train = best_model.predict(X_train)\n",
    "    pred_test = best_model.predict(X_test)\n",
    "\n",
    "    # Inverse transform predictions\n",
    "    pred_train_inv = target_scaler.inverse_transform(pred_train.reshape(-1, 1)).ravel()\n",
    "    y_train_inv = target_scaler.inverse_transform(y_train.reshape(-1, 1)).ravel()\n",
    "    pred_test_inv = target_scaler.inverse_transform(pred_test.reshape(-1, 1)).ravel()\n",
    "    y_test_inv = target_scaler.inverse_transform(y_test.reshape(-1, 1)).ravel()\n",
    "\n",
    "    # Evaluation\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train_inv, pred_train_inv))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test_inv, pred_test_inv))\n",
    "    train_r2 = r2_score(y_train_inv, pred_train_inv)\n",
    "    test_r2 = r2_score(y_test_inv, pred_test_inv)\n",
    "\n",
    "    print(f\"{feature_col} - Best Params: {grid_search.best_params_}\")\n",
    "    print(f\"{feature_col} - Train RMSE: {train_rmse:.4f}, R²: {train_r2:.4f}\")\n",
    "    print(f\"{feature_col} - Test  RMSE: {test_rmse:.4f}, R²: {test_r2:.4f}\")\n",
    "\n",
    "    # Optional: plotting\n",
    "    # if plot:\n",
    "    #     plt.figure(figsize=(10, 4))\n",
    "    #     plt.plot(y_test_inv, label=\"Actual\")\n",
    "    #     plt.plot(pred_test_inv, label=\"Predicted\")\n",
    "    #     plt.title(f\"{feature_col} Prediction (NGBoost with GridSearch)\")\n",
    "    #     plt.legend()\n",
    "    #     plt.show()\n",
    "\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb895dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training NGBoost for Service 1 - CPU Usage with test size 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "check_X_y() got an unexpected keyword argument 'ensure_all_finite'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_size \u001b[38;5;129;01min\u001b[39;00m test_sizes:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining NGBoost for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - CPU Usage with test size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     model_cpu \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ngboost_with_gridsearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCPU Usage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining NGBoost for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Memory Usage with test size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m     model_mem \u001b[38;5;241m=\u001b[39m train_ngboost_with_gridsearch(df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMemory Usage\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_size)\n",
      "Cell \u001b[1;32mIn[75], line 31\u001b[0m, in \u001b[0;36mtrain_ngboost_with_gridsearch\u001b[1;34m(df, feature_col, test_size, plot)\u001b[0m\n\u001b[0;32m     29\u001b[0m base_model \u001b[38;5;241m=\u001b[39m NGBRegressor(Dist\u001b[38;5;241m=\u001b[39mNormal, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(base_model, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Predictions\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1006\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    995\u001b[0m     raise ValueError(\n\u001b[0;32m    996\u001b[0m         \"cv.split and cv.get_n_splits returned \"\n\u001b[0;32m    997\u001b[0m         \"inconsistent results. Expected {} \"\n\u001b[0;32m    998\u001b[0m         \"splits, got {}\".format(n_splits, len(out) // n_candidates)\n\u001b[0;32m    999\u001b[0m     )\n\u001b[0;32m   1001\u001b[0m _warn_or_raise_about_fit_failures(out, self.error_score)\n\u001b[0;32m   1003\u001b[0m # For callable self.scoring, the return type is only know after\n\u001b[0;32m   1004\u001b[0m # calling. If the return type is a dictionary, the error scores\n\u001b[0;32m   1005\u001b[0m # can now be inserted with the correct key. The type checking\n\u001b[1;32m-> 1006\u001b[0m # of out will be done in `_insert_error_scores`.\n\u001b[0;32m   1007\u001b[0m if callable(self.scoring):\n\u001b[0;32m   1008\u001b[0m     _insert_error_scores(out, self.error_score)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\ngboost\\ngboost.py:258\u001b[0m, in \u001b[0;36mNGBoost.fit\u001b[1;34m(self, X, Y, X_val, Y_val, sample_weight, val_sample_weight, train_loss_monitor, val_loss_monitor, early_stopping_rounds)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscalings \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol_idxs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loss_monitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loss_monitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loss_monitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loss_monitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\ngboost\\ngboost.py:384\u001b[0m, in \u001b[0;36mNGBoost.partial_fit\u001b[1;34m(self, X, Y, X_val, Y_val, sample_weight, val_sample_weight, train_loss_monitor, val_loss_monitor, early_stopping_rounds)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 384\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    395\u001b[0m loss_list \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mTypeError\u001b[0m: check_X_y() got an unexpected keyword argument 'ensure_all_finite'"
     ]
    }
   ],
   "source": [
    "\n",
    "for name, df in configs.items():\n",
    "    for test_size in test_sizes:\n",
    "        print(f\"Training NGBoost for {name} - CPU Usage with test size {test_size}\")\n",
    "        model_cpu = train_ngboost_with_gridsearch(df, \"CPU Usage\", test_size)\n",
    "\n",
    "        print(f\"Training NGBoost for {name} - Memory Usage with test size {test_size}\")\n",
    "        model_mem = train_ngboost_with_gridsearch(df, \"Memory Usage\", test_size)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f21cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
