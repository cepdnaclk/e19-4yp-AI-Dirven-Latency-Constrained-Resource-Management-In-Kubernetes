{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "092039ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4cdf7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Timestamp', 'Service', 'CPU Request', 'Memory Request', 'CPU Limit',\n",
      "       'Memory Limit', 'Latency', 'CPU Usage', 'Memory Usage'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Paths to service1 datasets\n",
    "cpu_path_s1 = \"../../results/prometheus_data/service1_cpu_limit_reduction.csv\"\n",
    "memory_path_s1 = \"../../results/prometheus_data/new datasets/service1_memory_limit_reduction.csv\"\n",
    "both_path_s1 = \"../../results/prometheus_data/service1_both_limits_reduction.csv\"\n",
    "\n",
    "# Import datasets\n",
    "df_cpu_s1 = pd.read_csv(cpu_path_s1)\n",
    "df_memory_s1 = pd.read_csv(memory_path_s1)\n",
    "df_both_s1 = pd.read_csv(both_path_s1)\n",
    "\n",
    "df_all_s1 = pd.concat([df_cpu_s1, df_memory_s1, df_both_s1], ignore_index=True)\n",
    "print(df_all_s1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a782394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to service1 datasets\n",
    "cpu_path_s2 = \"../../results/prometheus_data/service2_cpu_limit_reduction.csv\"\n",
    "memory_path_s2 = \"../../results/prometheus_data/service2_memory_limit_reduction.csv\"\n",
    "both_path_s2 = \"../../results/prometheus_data/service2_both_limit_reduction.csv\"\n",
    "\n",
    "# Import datasets\n",
    "df_cpu_s2 = pd.read_csv(cpu_path_s2)\n",
    "df_memory_s2 = pd.read_csv(memory_path_s2)\n",
    "df_both_s2 = pd.read_csv(both_path_s2)\n",
    "\n",
    "# Combine all three DataFrames\n",
    "df_all_s2 = pd.concat([df_cpu_s2, df_memory_s2, df_both_s2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a97cc252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to datasets\n",
    "cpu_path_hg = \"../../results/prometheus_data/hashgen_cpu_limit_reduction.csv\"\n",
    "memory_path_hg = \"../../results/prometheus_data/hashgen_memory_limit_reduction.csv\"\n",
    "both_path_hg = \"../../results/prometheus_data/hashgen_both_limit_reduction.csv\"\n",
    "\n",
    "# Import datasets\n",
    "df_cpu_hg = pd.read_csv(cpu_path_hg)\n",
    "df_memory_hg = pd.read_csv(memory_path_hg)\n",
    "df_both_hg = pd.read_csv(both_path_hg)\n",
    "\n",
    "# Combine all three DataFrames\n",
    "df_all_hg = pd.concat([df_cpu_hg, df_memory_hg, df_both_hg], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "723de441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to datasets\n",
    "cpu_path_rp = \"../../results/prometheus_data/ranspw_cpu_limit_reduction.csv\"\n",
    "memory_path_rp = \"../../results/prometheus_data/randpw_memory_limit_reduction.csv\"\n",
    "both_path_rp = \"../../results/prometheus_data/randpw_both_limits_reduction.csv\"\n",
    "\n",
    "# Import datasets\n",
    "df_cpu_rp = pd.read_csv(cpu_path_rp)\n",
    "df_memory_rp = pd.read_csv(memory_path_rp)\n",
    "df_both_rp = pd.read_csv(both_path_rp)\n",
    "\n",
    "# Combine all three DataFrames\n",
    "df_all_rp = pd.concat([df_cpu_rp, df_memory_rp, df_both_rp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e3a6c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_random_forest(df, target_column, test_size, random_state=42):\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Select numeric features only (adjust if you want categorical encoding)\n",
    "    X = X.select_dtypes(include=['number'])\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('rf', RandomForestRegressor(n_estimators=100, random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    train_score = r2_score(y_train, y_train_pred)\n",
    "    test_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6689c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test size: 0.3\n",
      "CPU Usage R² Train - Service 1: 0.9992\n",
      "CPU Usage R² Test  - Service 1: 0.9963\n",
      "Memory Usage R² Train - Service 1: 0.9587\n",
      "Memory Usage R² Test  - Service 1: 0.7567\n",
      "CPU Usage R² Train - Service 2: 0.9988\n",
      "CPU Usage R² Test  - Service 2: 0.9920\n",
      "Memory Usage R² Train - Service 2: 0.9200\n",
      "Memory Usage R² Test  - Service 2: 0.4245\n",
      "CPU Usage R² Train - HashGen: 0.9992\n",
      "CPU Usage R² Test  - HashGen: 0.9943\n",
      "Memory Usage R² Train - HashGen: 0.9339\n",
      "Memory Usage R² Test  - HashGen: 0.5385\n",
      "CPU Usage R² Train - RandPw: 0.9934\n",
      "CPU Usage R² Test  - RandPw: 0.9644\n",
      "Memory Usage R² Train - RandPw: 0.9999\n",
      "Memory Usage R² Test  - RandPw: 0.9993\n",
      "\n",
      "Test size: 0.2\n",
      "CPU Usage R² Train - Service 1: 0.9993\n",
      "CPU Usage R² Test  - Service 1: 0.9961\n",
      "Memory Usage R² Train - Service 1: 0.9660\n",
      "Memory Usage R² Test  - Service 1: 0.7416\n",
      "CPU Usage R² Train - Service 2: 0.9990\n",
      "CPU Usage R² Test  - Service 2: 0.9935\n",
      "Memory Usage R² Train - Service 2: 0.9244\n",
      "Memory Usage R² Test  - Service 2: 0.4674\n",
      "CPU Usage R² Train - HashGen: 0.9993\n",
      "CPU Usage R² Test  - HashGen: 0.9949\n",
      "Memory Usage R² Train - HashGen: 0.9373\n",
      "Memory Usage R² Test  - HashGen: 0.5964\n",
      "CPU Usage R² Train - RandPw: 0.9945\n",
      "CPU Usage R² Test  - RandPw: 0.9770\n",
      "Memory Usage R² Train - RandPw: 0.9999\n",
      "Memory Usage R² Test  - RandPw: 0.9998\n",
      "\n",
      "Test size: 0.1\n",
      "CPU Usage R² Train - Service 1: 0.9993\n",
      "CPU Usage R² Test  - Service 1: 0.9973\n",
      "Memory Usage R² Train - Service 1: 0.9610\n",
      "Memory Usage R² Test  - Service 1: 0.8938\n",
      "CPU Usage R² Train - Service 2: 0.9990\n",
      "CPU Usage R² Test  - Service 2: 0.9941\n",
      "Memory Usage R² Train - Service 2: 0.9268\n",
      "Memory Usage R² Test  - Service 2: 0.5548\n",
      "CPU Usage R² Train - HashGen: 0.9994\n",
      "CPU Usage R² Test  - HashGen: 0.9954\n",
      "Memory Usage R² Train - HashGen: 0.9438\n",
      "Memory Usage R² Test  - HashGen: 0.6285\n",
      "CPU Usage R² Train - RandPw: 0.9952\n",
      "CPU Usage R² Test  - RandPw: 0.9795\n",
      "Memory Usage R² Train - RandPw: 0.9998\n",
      "Memory Usage R² Test  - RandPw: 1.0000\n"
     ]
    }
   ],
   "source": [
    "configs = {\n",
    "    \"Service 1\": df_all_s1,\n",
    "    \"Service 2\": df_all_s2,\n",
    "    \"HashGen\": df_all_hg,\n",
    "    \"RandPw\": df_all_rp,\n",
    "}\n",
    "\n",
    "test_sizes = [0.3, 0.2, 0.1]\n",
    "\n",
    "for test_size in test_sizes:\n",
    "    print(f\"\\nTest size: {test_size}\")\n",
    "    for label, df in configs.items():\n",
    "        cpu_train_score, cpu_test_score = evaluate_random_forest(df, 'CPU Usage', test_size)\n",
    "        mem_train_score, mem_test_score = evaluate_random_forest(df, 'Memory Usage', test_size)\n",
    "\n",
    "        print(f\"CPU Usage R² Train - {label}: {cpu_train_score:.4f}\")\n",
    "        print(f\"CPU Usage R² Test  - {label}: {cpu_test_score:.4f}\")\n",
    "        print(f\"Memory Usage R² Train - {label}: {mem_train_score:.4f}\")\n",
    "        print(f\"Memory Usage R² Test  - {label}: {mem_test_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1d1f47",
   "metadata": {},
   "source": [
    "For Memory Usage, the training R² scores are consistently high (above 0.9), showing that the model fits the training data very closely.\n",
    "\n",
    "However, the test R² scores drop significantly (sometimes below 0.6), indicating the model struggles to generalize to new data.\n",
    "\n",
    "This large gap between training and test performance is a classic sign of overfitting. The model is too tailored to the training set specifics and cannot accurately predict unseen examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c4a10bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def evaluate_random_forest_new(df, target_column, test_size=0.2, random_state=42,\n",
    "                           max_depth=5, min_samples_split=2, min_samples_leaf=2, cv=5):\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    X = X.select_dtypes(include=['number'])\n",
    "\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('rf', model)\n",
    "    ])\n",
    "\n",
    "    # Perform cross-validation on full data for better generalization estimate\n",
    "    cv_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='r2')\n",
    "\n",
    "    # Also, get train/test split score for comparison\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    train_score = r2_score(y_train, y_train_pred)\n",
    "    test_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    return {\n",
    "        \"cv_mean_score\": cv_scores.mean(),\n",
    "        \"cv_std_score\": cv_scores.std(),\n",
    "        \"train_score\": train_score,\n",
    "        \"test_score\": test_score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d68d56a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test size: 0.3\n",
      "CPU Usage R² Train - Service 1: 0.9646\n",
      "CPU Usage R² Test  - Service 1: 0.9540\n",
      "CPU Usage CV Mean R² - Service 1: -12.1674 ± 24.0663\n",
      "Memory Usage R² Train - Service 1: 0.7689\n",
      "Memory Usage R² Test  - Service 1: 0.7662\n",
      "Memory Usage CV Mean R² - Service 1: -3.4206 ± 5.7981\n",
      "\n",
      "CPU Usage R² Train - Service 2: 0.9863\n",
      "CPU Usage R² Test  - Service 2: 0.9851\n",
      "CPU Usage CV Mean R² - Service 2: 0.5980 ± 0.3536\n",
      "Memory Usage R² Train - Service 2: 0.2458\n",
      "Memory Usage R² Test  - Service 2: 0.1808\n",
      "Memory Usage CV Mean R² - Service 2: -0.5560 ± 0.2762\n",
      "\n",
      "CPU Usage R² Train - HashGen: 0.9858\n",
      "CPU Usage R² Test  - HashGen: 0.9841\n",
      "CPU Usage CV Mean R² - HashGen: 0.7958 ± 0.0451\n",
      "Memory Usage R² Train - HashGen: 0.4242\n",
      "Memory Usage R² Test  - HashGen: 0.3307\n",
      "Memory Usage CV Mean R² - HashGen: -0.8824 ± 1.2092\n",
      "\n",
      "CPU Usage R² Train - RandPw: 0.7550\n",
      "CPU Usage R² Test  - RandPw: 0.7153\n",
      "CPU Usage CV Mean R² - RandPw: -0.1028 ± 0.2873\n",
      "Memory Usage R² Train - RandPw: 0.9427\n",
      "Memory Usage R² Test  - RandPw: 0.9554\n",
      "Memory Usage CV Mean R² - RandPw: -1.5768 ± 3.9979\n",
      "\n",
      "\n",
      "Test size: 0.2\n",
      "CPU Usage R² Train - Service 1: 0.9663\n",
      "CPU Usage R² Test  - Service 1: 0.9523\n",
      "CPU Usage CV Mean R² - Service 1: -12.1674 ± 24.0663\n",
      "Memory Usage R² Train - Service 1: 0.7979\n",
      "Memory Usage R² Test  - Service 1: 0.6885\n",
      "Memory Usage CV Mean R² - Service 1: -3.4206 ± 5.7981\n",
      "\n",
      "CPU Usage R² Train - Service 2: 0.9864\n",
      "CPU Usage R² Test  - Service 2: 0.9864\n",
      "CPU Usage CV Mean R² - Service 2: 0.5980 ± 0.3536\n",
      "Memory Usage R² Train - Service 2: 0.2325\n",
      "Memory Usage R² Test  - Service 2: 0.1902\n",
      "Memory Usage CV Mean R² - Service 2: -0.5560 ± 0.2762\n",
      "\n",
      "CPU Usage R² Train - HashGen: 0.9852\n",
      "CPU Usage R² Test  - HashGen: 0.9840\n",
      "CPU Usage CV Mean R² - HashGen: 0.7958 ± 0.0451\n",
      "Memory Usage R² Train - HashGen: 0.3979\n",
      "Memory Usage R² Test  - HashGen: 0.3220\n",
      "Memory Usage CV Mean R² - HashGen: -0.8824 ± 1.2092\n",
      "\n",
      "CPU Usage R² Train - RandPw: 0.7432\n",
      "CPU Usage R² Test  - RandPw: 0.7437\n",
      "CPU Usage CV Mean R² - RandPw: -0.1028 ± 0.2873\n",
      "Memory Usage R² Train - RandPw: 0.9450\n",
      "Memory Usage R² Test  - RandPw: 0.9530\n",
      "Memory Usage CV Mean R² - RandPw: -1.5768 ± 3.9979\n",
      "\n",
      "\n",
      "Test size: 0.1\n",
      "CPU Usage R² Train - Service 1: 0.9644\n",
      "CPU Usage R² Test  - Service 1: 0.9655\n",
      "CPU Usage CV Mean R² - Service 1: -12.1674 ± 24.0663\n",
      "Memory Usage R² Train - Service 1: 0.7872\n",
      "Memory Usage R² Test  - Service 1: 0.7684\n",
      "Memory Usage CV Mean R² - Service 1: -3.4206 ± 5.7981\n",
      "\n",
      "CPU Usage R² Train - Service 2: 0.9863\n",
      "CPU Usage R² Test  - Service 2: 0.9814\n",
      "CPU Usage CV Mean R² - Service 2: 0.5980 ± 0.3536\n",
      "Memory Usage R² Train - Service 2: 0.2349\n",
      "Memory Usage R² Test  - Service 2: 0.2334\n",
      "Memory Usage CV Mean R² - Service 2: -0.5560 ± 0.2762\n",
      "\n",
      "CPU Usage R² Train - HashGen: 0.9855\n",
      "CPU Usage R² Test  - HashGen: 0.9849\n",
      "CPU Usage CV Mean R² - HashGen: 0.7958 ± 0.0451\n",
      "Memory Usage R² Train - HashGen: 0.3914\n",
      "Memory Usage R² Test  - HashGen: 0.3353\n",
      "Memory Usage CV Mean R² - HashGen: -0.8824 ± 1.2092\n",
      "\n",
      "CPU Usage R² Train - RandPw: 0.7498\n",
      "CPU Usage R² Test  - RandPw: 0.7515\n",
      "CPU Usage CV Mean R² - RandPw: -0.1028 ± 0.2873\n",
      "Memory Usage R² Train - RandPw: 0.9449\n",
      "Memory Usage R² Test  - RandPw: 0.9574\n",
      "Memory Usage CV Mean R² - RandPw: -1.5768 ± 3.9979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "configs = {\n",
    "    \"Service 1\": df_all_s1,\n",
    "    \"Service 2\": df_all_s2,\n",
    "    \"HashGen\": df_all_hg,\n",
    "    \"RandPw\": df_all_rp,\n",
    "}\n",
    "\n",
    "test_sizes = [0.3, 0.2, 0.1]\n",
    "\n",
    "for test_size in test_sizes:\n",
    "    print(f\"\\nTest size: {test_size}\")\n",
    "    for label, df in configs.items():\n",
    "        cpu_results = evaluate_random_forest_new(df, 'CPU Usage', test_size)\n",
    "        mem_results = evaluate_random_forest_new(df, 'Memory Usage', test_size)\n",
    "\n",
    "        print(f\"CPU Usage R² Train - {label}: {cpu_results['train_score']:.4f}\")\n",
    "        print(f\"CPU Usage R² Test  - {label}: {cpu_results['test_score']:.4f}\")\n",
    "        print(f\"CPU Usage CV Mean R² - {label}: {cpu_results['cv_mean_score']:.4f} ± {cpu_results['cv_std_score']:.4f}\")\n",
    "\n",
    "        print(f\"Memory Usage R² Train - {label}: {mem_results['train_score']:.4f}\")\n",
    "        print(f\"Memory Usage R² Test  - {label}: {mem_results['test_score']:.4f}\")\n",
    "        print(f\"Memory Usage CV Mean R² - {label}: {mem_results['cv_mean_score']:.4f} ± {mem_results['cv_std_score']:.4f}\")\n",
    "        print()  # Add a blank line between services for readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fedaa8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rolling_features(df, window=3):\n",
    "    df = df.copy()\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "    df = df.sort_values(['Service', 'Timestamp'])  # Service-wise time sorting\n",
    "    df.set_index('Timestamp', inplace=True)\n",
    "\n",
    "    # Rolling averages per service\n",
    "    for col in ['CPU Usage', 'Memory Usage', 'Latency']:\n",
    "        df[f'{col}_RollingMean'] = df.groupby('Service')[col].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "        df[f'{col}_RollingSTD'] = df.groupby('Service')[col].transform(lambda x: x.rolling(window, min_periods=1).std())\n",
    "\n",
    "    # Spike detection\n",
    "    df[\"CPU_Spike\"] = df[\"CPU Usage\"] - df[\"CPU Usage_RollingMean\"]\n",
    "    df[\"Memory_Spike\"] = df[\"Memory Usage\"] - df[\"Memory Usage_RollingMean\"]\n",
    "\n",
    "    # Latency trend direction\n",
    "    df[\"Latency_Trend\"] = df.groupby(\"Service\")[\"Latency\"].transform(lambda x: x.diff().fillna(0).apply(lambda y: 1 if y > 0 else (-1 if y < 0 else 0)))\n",
    "\n",
    "    df.reset_index(inplace=True)  # Reset index to include Timestamp again\n",
    "    df.dropna(inplace=True)  # Optional: drop rows with NaNs from rolling\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf62e2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_random_forest_with_grid_search(df, target_column, test_size=0.2, random_state=42, cv=5):\n",
    "    df = add_rolling_features(df)\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='mixed')\n",
    "\n",
    "    X = df.drop(columns=[target_column, 'Timestamp', 'Service'])  # Drop non-numeric/time/grouping columns\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Keep only numeric features\n",
    "    X = X.select_dtypes(include=['number'])\n",
    "\n",
    "    # Define pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('rf', RandomForestRegressor(random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    # Grid search parameters\n",
    "    param_grid = {\n",
    "        'rf__max_depth': [3, 5, 10],\n",
    "        'rf__min_samples_split': [2, 5, 10],\n",
    "        'rf__min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    # Grid search\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        scoring='r2',\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = best_pipeline.predict(X_train)\n",
    "    y_test_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "    train_score = r2_score(y_train, y_train_pred)\n",
    "    test_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    return {\n",
    "        \"best_params\": best_params,\n",
    "        \"cv_best_score\": grid_search.best_score_,\n",
    "        \"train_score\": train_score,\n",
    "        \"test_score\": test_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91bcfdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test size: 0.3\n",
      "Service 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "time data \"2025-05-12T01:01:04\" doesn't match format \"%Y-%m-%dT%H:%M:%S.%f\", at position 1298. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label, df \u001b[38;5;129;01min\u001b[39;00m configs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(label)\n\u001b[1;32m----> 7\u001b[0m     cpu_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_random_forest_with_grid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCPU Usage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     mem_results \u001b[38;5;241m=\u001b[39m evaluate_random_forest_with_grid_search(df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMemory Usage\u001b[39m\u001b[38;5;124m'\u001b[39m, test_size)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCPU Usage R² Train - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcpu_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[53], line 2\u001b[0m, in \u001b[0;36mevaluate_random_forest_with_grid_search\u001b[1;34m(df, target_column, test_size, random_state, cv)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_random_forest_with_grid_search\u001b[39m(df, target_column, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43madd_rolling_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[target_column, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mService\u001b[39m\u001b[38;5;124m'\u001b[39m])  \u001b[38;5;66;03m# Drop non-numeric/time/grouping columns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     y \u001b[38;5;241m=\u001b[39m df[target_column]\n",
      "Cell \u001b[1;32mIn[52], line 3\u001b[0m, in \u001b[0;36madd_rolling_features\u001b[1;34m(df, window)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_rolling_features\u001b[39m(df, window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m      2\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m----> 3\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTimestamp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mService\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m])  \u001b[38;5;66;03m# Service-wise time sorting\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1067\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1067\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1068\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[0;32m    436\u001b[0m     arg,\n\u001b[0;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    442\u001b[0m )\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[0;32m    457\u001b[0m     arg,\n\u001b[0;32m    458\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[0;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mstrptime.pyx:501\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:451\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:583\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data \"2025-05-12T01:01:04\" doesn't match format \"%Y-%m-%dT%H:%M:%S.%f\", at position 1298. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "test_sizes = [0.3, 0.2, 0.1]\n",
    "\n",
    "for test_size in test_sizes:\n",
    "    print(f\"\\nTest size: {test_size}\")\n",
    "    for label, df in configs.items():\n",
    "        print(label)\n",
    "        cpu_results = evaluate_random_forest_with_grid_search(df, 'CPU Usage', test_size)\n",
    "        mem_results = evaluate_random_forest_with_grid_search(df, 'Memory Usage', test_size)\n",
    "\n",
    "        print(f\"CPU Usage R² Train - {label}: {cpu_results['train_score']:.4f}\")\n",
    "        print(f\"CPU Usage R² Test  - {label}: {cpu_results['test_score']:.4f}\")\n",
    "        print(f\"CPU Usage CV R² - {label}: {cpu_results['cv_best_score']:.4f}\")\n",
    "        print(f\"Best Params - {label}: {cpu_results['best_params']}\")\n",
    "\n",
    "\n",
    "        print(f\"Memory Usage R² Train - {label}: {mem_results['train_score']:.4f}\")\n",
    "        print(f\"Memory Usage R² Test  - {label}: {mem_results['test_score']:.4f}\")\n",
    "        print(f\"Memory Usage CV R² - {label}: {mem_results['cv_best_score']:.4f}\")\n",
    "        print(f\"Best Params - {label}: {mem_results['best_params']}\")\n",
    "\n",
    "        print()  # Add a blank line between services for readability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
