{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "092039ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4cdf7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Timestamp', 'Service', 'CPU Request', 'Memory Request', 'CPU Limit',\n",
      "       'Memory Limit', 'Latency', 'CPU Usage', 'Memory Usage'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Paths to service1 datasets\n",
    "cpu_path_s1 = \"../../results/prometheus_data/service1_cpu_limit_reduction.csv\"\n",
    "memory_path_s1 = \"../../results/prometheus_data/new datasets/service1_memory_limit_reduction.csv\"\n",
    "both_path_s1 = \"../../results/prometheus_data/service1_both_limits_reduction.csv\"\n",
    "\n",
    "# Import datasets\n",
    "df_cpu_s1 = pd.read_csv(cpu_path_s1)\n",
    "df_memory_s1 = pd.read_csv(memory_path_s1)\n",
    "df_both_s1 = pd.read_csv(both_path_s1)\n",
    "\n",
    "df_all_s1 = pd.concat([df_cpu_s1, df_memory_s1, df_both_s1], ignore_index=True)\n",
    "print(df_all_s1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a782394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to service1 datasets\n",
    "cpu_path_s2 = \"../../results/prometheus_data/service2_cpu_limit_reduction.csv\"\n",
    "memory_path_s2 = \"../../results/prometheus_data/service2_memory_limit_reduction.csv\"\n",
    "both_path_s2 = \"../../results/prometheus_data/service2_both_limit_reduction.csv\"\n",
    "\n",
    "# Import datasets\n",
    "df_cpu_s2 = pd.read_csv(cpu_path_s2)\n",
    "df_memory_s2 = pd.read_csv(memory_path_s2)\n",
    "df_both_s2 = pd.read_csv(both_path_s2)\n",
    "\n",
    "# Combine all three DataFrames\n",
    "df_all_s2 = pd.concat([df_cpu_s2, df_memory_s2, df_both_s2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a97cc252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to datasets\n",
    "cpu_path_hg = \"../../results/prometheus_data/hashgen_cpu_limit_reduction.csv\"\n",
    "memory_path_hg = \"../../results/prometheus_data/hashgen_memory_limit_reduction.csv\"\n",
    "both_path_hg = \"../../results/prometheus_data/hashgen_both_limit_reduction.csv\"\n",
    "\n",
    "# Import datasets\n",
    "df_cpu_hg = pd.read_csv(cpu_path_hg)\n",
    "df_memory_hg = pd.read_csv(memory_path_hg)\n",
    "df_both_hg = pd.read_csv(both_path_hg)\n",
    "\n",
    "# Combine all three DataFrames\n",
    "df_all_hg = pd.concat([df_cpu_hg, df_memory_hg, df_both_hg], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "723de441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to datasets\n",
    "cpu_path_rp = \"../../results/prometheus_data/ranspw_cpu_limit_reduction.csv\"\n",
    "memory_path_rp = \"../../results/prometheus_data/randpw_memory_limit_reduction.csv\"\n",
    "both_path_rp = \"../../results/prometheus_data/randpw_both_limits_reduction.csv\"\n",
    "\n",
    "# Import datasets\n",
    "df_cpu_rp = pd.read_csv(cpu_path_rp)\n",
    "df_memory_rp = pd.read_csv(memory_path_rp)\n",
    "df_both_rp = pd.read_csv(both_path_rp)\n",
    "\n",
    "# Combine all three DataFrames\n",
    "df_all_rp = pd.concat([df_cpu_rp, df_memory_rp, df_both_rp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e3a6c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_random_forest(df, target_column, test_size, random_state=42):\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Select numeric features only (adjust if you want categorical encoding)\n",
    "    X = X.select_dtypes(include=['number'])\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('rf', RandomForestRegressor(n_estimators=100, random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    train_score = r2_score(y_train, y_train_pred)\n",
    "    test_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6689c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test size: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Usage R² Train - Service 1: 0.9992\n",
      "CPU Usage R² Test  - Service 1: 0.3658\n",
      "Memory Usage R² Train - Service 1: 0.9794\n",
      "Memory Usage R² Test  - Service 1: -0.9368\n",
      "CPU Usage R² Train - Service 2: 0.9991\n",
      "CPU Usage R² Test  - Service 2: 0.9092\n",
      "Memory Usage R² Train - Service 2: 0.9331\n",
      "Memory Usage R² Test  - Service 2: -0.3706\n",
      "CPU Usage R² Train - HashGen: 0.9993\n",
      "CPU Usage R² Test  - HashGen: 0.7887\n",
      "Memory Usage R² Train - HashGen: 0.9357\n",
      "Memory Usage R² Test  - HashGen: -0.5123\n",
      "CPU Usage R² Train - RandPw: 0.9964\n",
      "CPU Usage R² Test  - RandPw: -1.6225\n",
      "Memory Usage R² Train - RandPw: 0.9998\n",
      "Memory Usage R² Test  - RandPw: 0.1483\n",
      "\n",
      "Test size: 0.2\n",
      "CPU Usage R² Train - Service 1: 0.9990\n",
      "CPU Usage R² Test  - Service 1: -0.6166\n",
      "Memory Usage R² Train - Service 1: 0.9804\n",
      "Memory Usage R² Test  - Service 1: -0.5345\n",
      "CPU Usage R² Train - Service 2: 0.9990\n",
      "CPU Usage R² Test  - Service 2: 0.8234\n",
      "Memory Usage R² Train - Service 2: 0.9334\n",
      "Memory Usage R² Test  - Service 2: -0.2144\n",
      "CPU Usage R² Train - HashGen: 0.9993\n",
      "CPU Usage R² Test  - HashGen: 0.7320\n",
      "Memory Usage R² Train - HashGen: 0.9380\n",
      "Memory Usage R² Test  - HashGen: -0.6826\n",
      "CPU Usage R² Train - RandPw: 0.9957\n",
      "CPU Usage R² Test  - RandPw: -2.1779\n",
      "Memory Usage R² Train - RandPw: 0.9998\n",
      "Memory Usage R² Test  - RandPw: -0.1407\n",
      "\n",
      "Test size: 0.1\n",
      "CPU Usage R² Train - Service 1: 0.9992\n",
      "CPU Usage R² Test  - Service 1: -1.5170\n",
      "Memory Usage R² Train - Service 1: 0.9809\n",
      "Memory Usage R² Test  - Service 1: -0.2363\n",
      "CPU Usage R² Train - Service 2: 0.9990\n",
      "CPU Usage R² Test  - Service 2: 0.3515\n",
      "Memory Usage R² Train - Service 2: 0.9317\n",
      "Memory Usage R² Test  - Service 2: -0.5969\n",
      "CPU Usage R² Train - HashGen: 0.9993\n",
      "CPU Usage R² Test  - HashGen: 0.2180\n",
      "Memory Usage R² Train - HashGen: 0.9388\n",
      "Memory Usage R² Test  - HashGen: -0.9647\n",
      "CPU Usage R² Train - RandPw: 0.9958\n",
      "CPU Usage R² Test  - RandPw: -3.6719\n",
      "Memory Usage R² Train - RandPw: 0.9999\n",
      "Memory Usage R² Test  - RandPw: -18.1704\n"
     ]
    }
   ],
   "source": [
    "configs = {\n",
    "    \"Service 1\": df_all_s1,\n",
    "    \"Service 2\": df_all_s2,\n",
    "    \"HashGen\": df_all_hg,\n",
    "    \"RandPw\": df_all_rp,\n",
    "}\n",
    "\n",
    "test_sizes = [0.3, 0.2, 0.1]\n",
    "\n",
    "for test_size in test_sizes:\n",
    "    print(f\"\\nTest size: {test_size}\")\n",
    "    for label, df in configs.items():\n",
    "        cpu_train_score, cpu_test_score = evaluate_random_forest(df, 'CPU Usage', test_size)\n",
    "        mem_train_score, mem_test_score = evaluate_random_forest(df, 'Memory Usage', test_size)\n",
    "\n",
    "        print(f\"CPU Usage R² Train - {label}: {cpu_train_score:.4f}\")\n",
    "        print(f\"CPU Usage R² Test  - {label}: {cpu_test_score:.4f}\")\n",
    "        print(f\"Memory Usage R² Train - {label}: {mem_train_score:.4f}\")\n",
    "        print(f\"Memory Usage R² Test  - {label}: {mem_test_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1d1f47",
   "metadata": {},
   "source": [
    "For Memory Usage, the training R² scores are consistently high (above 0.9), showing that the model fits the training data very closely.\n",
    "\n",
    "However, the test R² scores drop significantly (sometimes below 0.6), indicating the model struggles to generalize to new data.\n",
    "\n",
    "This large gap between training and test performance is a classic sign of overfitting. The model is too tailored to the training set specifics and cannot accurately predict unseen examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4a10bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def evaluate_random_forest_new(df, target_column, test_size=0.2, random_state=42,\n",
    "                           max_depth=5, min_samples_split=2, min_samples_leaf=2, cv=5):\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    X = X.select_dtypes(include=['number'])\n",
    "\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('rf', model)\n",
    "    ])\n",
    "\n",
    "    # Perform cross-validation on full data for better generalization estimate\n",
    "    cv_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='r2')\n",
    "\n",
    "    # Also, get train/test split score for comparison\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    train_score = r2_score(y_train, y_train_pred)\n",
    "    test_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    return {\n",
    "        \"cv_mean_score\": cv_scores.mean(),\n",
    "        \"cv_std_score\": cv_scores.std(),\n",
    "        \"train_score\": train_score,\n",
    "        \"test_score\": test_score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d68d56a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test size: 0.3\n",
      "CPU Usage R² Train - Service 1: 0.9788\n",
      "CPU Usage R² Test  - Service 1: 0.3680\n",
      "CPU Usage CV Mean R² - Service 1: -12.1674 ± 24.0663\n",
      "Memory Usage R² Train - Service 1: 0.8183\n",
      "Memory Usage R² Test  - Service 1: -0.6169\n",
      "Memory Usage CV Mean R² - Service 1: -3.4206 ± 5.7981\n",
      "\n",
      "CPU Usage R² Train - Service 2: 0.9886\n",
      "CPU Usage R² Test  - Service 2: 0.9090\n",
      "CPU Usage CV Mean R² - Service 2: 0.5980 ± 0.3536\n",
      "Memory Usage R² Train - Service 2: 0.3361\n",
      "Memory Usage R² Test  - Service 2: -0.4684\n",
      "Memory Usage CV Mean R² - Service 2: -0.5560 ± 0.2762\n",
      "\n",
      "CPU Usage R² Train - HashGen: 0.9896\n",
      "CPU Usage R² Test  - HashGen: 0.8102\n",
      "CPU Usage CV Mean R² - HashGen: 0.7958 ± 0.0451\n",
      "Memory Usage R² Train - HashGen: 0.4894\n",
      "Memory Usage R² Test  - HashGen: 0.1107\n",
      "Memory Usage CV Mean R² - HashGen: -0.8824 ± 1.2092\n",
      "\n",
      "CPU Usage R² Train - RandPw: 0.8736\n",
      "CPU Usage R² Test  - RandPw: -0.6859\n",
      "CPU Usage CV Mean R² - RandPw: -0.1028 ± 0.2873\n",
      "Memory Usage R² Train - RandPw: 0.9908\n",
      "Memory Usage R² Test  - RandPw: 0.1435\n",
      "Memory Usage CV Mean R² - RandPw: -1.5768 ± 3.9979\n",
      "\n",
      "\n",
      "Test size: 0.2\n",
      "CPU Usage R² Train - Service 1: 0.9724\n",
      "CPU Usage R² Test  - Service 1: -0.6029\n",
      "CPU Usage CV Mean R² - Service 1: -12.1674 ± 24.0663\n",
      "Memory Usage R² Train - Service 1: 0.8230\n",
      "Memory Usage R² Test  - Service 1: -0.2873\n",
      "Memory Usage CV Mean R² - Service 1: -3.4206 ± 5.7981\n",
      "\n",
      "CPU Usage R² Train - Service 2: 0.9870\n",
      "CPU Usage R² Test  - Service 2: 0.8306\n",
      "CPU Usage CV Mean R² - Service 2: 0.5980 ± 0.3536\n",
      "Memory Usage R² Train - Service 2: 0.2487\n",
      "Memory Usage R² Test  - Service 2: -0.2467\n",
      "Memory Usage CV Mean R² - Service 2: -0.5560 ± 0.2762\n",
      "\n",
      "CPU Usage R² Train - HashGen: 0.9881\n",
      "CPU Usage R² Test  - HashGen: 0.7639\n",
      "CPU Usage CV Mean R² - HashGen: 0.7958 ± 0.0451\n",
      "Memory Usage R² Train - HashGen: 0.4858\n",
      "Memory Usage R² Test  - HashGen: 0.0589\n",
      "Memory Usage CV Mean R² - HashGen: -0.8824 ± 1.2092\n",
      "\n",
      "CPU Usage R² Train - RandPw: 0.8269\n",
      "CPU Usage R² Test  - RandPw: -0.4912\n",
      "CPU Usage CV Mean R² - RandPw: -0.1028 ± 0.2873\n",
      "Memory Usage R² Train - RandPw: 0.9900\n",
      "Memory Usage R² Test  - RandPw: -0.1418\n",
      "Memory Usage CV Mean R² - RandPw: -1.5768 ± 3.9979\n",
      "\n",
      "\n",
      "Test size: 0.1\n",
      "CPU Usage R² Train - Service 1: 0.9702\n",
      "CPU Usage R² Test  - Service 1: -1.3674\n",
      "CPU Usage CV Mean R² - Service 1: -12.1674 ± 24.0663\n",
      "Memory Usage R² Train - Service 1: 0.8184\n",
      "Memory Usage R² Test  - Service 1: -0.1586\n",
      "Memory Usage CV Mean R² - Service 1: -3.4206 ± 5.7981\n",
      "\n",
      "CPU Usage R² Train - Service 2: 0.9839\n",
      "CPU Usage R² Test  - Service 2: 0.4053\n",
      "CPU Usage CV Mean R² - Service 2: 0.5980 ± 0.3536\n",
      "Memory Usage R² Train - Service 2: 0.2378\n",
      "Memory Usage R² Test  - Service 2: -0.5549\n",
      "Memory Usage CV Mean R² - Service 2: -0.5560 ± 0.2762\n",
      "\n",
      "CPU Usage R² Train - HashGen: 0.9867\n",
      "CPU Usage R² Test  - HashGen: 0.3121\n",
      "CPU Usage CV Mean R² - HashGen: 0.7958 ± 0.0451\n",
      "Memory Usage R² Train - HashGen: 0.4768\n",
      "Memory Usage R² Test  - HashGen: -0.0378\n",
      "Memory Usage CV Mean R² - HashGen: -0.8824 ± 1.2092\n",
      "\n",
      "CPU Usage R² Train - RandPw: 0.7787\n",
      "CPU Usage R² Test  - RandPw: -1.7913\n",
      "CPU Usage CV Mean R² - RandPw: -0.1028 ± 0.2873\n",
      "Memory Usage R² Train - RandPw: 0.9482\n",
      "Memory Usage R² Test  - RandPw: -16.8144\n",
      "Memory Usage CV Mean R² - RandPw: -1.5768 ± 3.9979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "configs = {\n",
    "    \"Service 1\": df_all_s1,\n",
    "    \"Service 2\": df_all_s2,\n",
    "    \"HashGen\": df_all_hg,\n",
    "    \"RandPw\": df_all_rp,\n",
    "}\n",
    "\n",
    "test_sizes = [0.3, 0.2, 0.1]\n",
    "\n",
    "for test_size in test_sizes:\n",
    "    print(f\"\\nTest size: {test_size}\")\n",
    "    for label, df in configs.items():\n",
    "        cpu_results = evaluate_random_forest_new(df, 'CPU Usage', test_size)\n",
    "        mem_results = evaluate_random_forest_new(df, 'Memory Usage', test_size)\n",
    "\n",
    "        print(f\"CPU Usage R² Train - {label}: {cpu_results['train_score']:.4f}\")\n",
    "        print(f\"CPU Usage R² Test  - {label}: {cpu_results['test_score']:.4f}\")\n",
    "        print(f\"CPU Usage CV Mean R² - {label}: {cpu_results['cv_mean_score']:.4f} ± {cpu_results['cv_std_score']:.4f}\")\n",
    "\n",
    "        print(f\"Memory Usage R² Train - {label}: {mem_results['train_score']:.4f}\")\n",
    "        print(f\"Memory Usage R² Test  - {label}: {mem_results['test_score']:.4f}\")\n",
    "        print(f\"Memory Usage CV Mean R² - {label}: {mem_results['cv_mean_score']:.4f} ± {mem_results['cv_std_score']:.4f}\")\n",
    "        print()  # Add a blank line between services for readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fedaa8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rolling_features(df, window=3):\n",
    "    df = df.copy()\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='mixed')\n",
    "\n",
    "    df = df.sort_values(['Service', 'Timestamp'])  # Service-wise time sorting\n",
    "    df.set_index('Timestamp', inplace=True)\n",
    "\n",
    "    # Rolling averages per service\n",
    "    for col in ['CPU Usage', 'Memory Usage', 'Latency']:\n",
    "        df[f'{col}_RollingMean'] = df.groupby('Service')[col].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "        df[f'{col}_RollingSTD'] = df.groupby('Service')[col].transform(lambda x: x.rolling(window, min_periods=1).std())\n",
    "\n",
    "    # Spike detection\n",
    "    df[\"CPU_Spike\"] = df[\"CPU Usage\"] - df[\"CPU Usage_RollingMean\"]\n",
    "    df[\"Memory_Spike\"] = df[\"Memory Usage\"] - df[\"Memory Usage_RollingMean\"]\n",
    "\n",
    "    # Latency trend direction\n",
    "    df[\"Latency_Trend\"] = df.groupby(\"Service\")[\"Latency\"].transform(lambda x: x.diff().fillna(0).apply(lambda y: 1 if y > 0 else (-1 if y < 0 else 0)))\n",
    "\n",
    "    df.reset_index(inplace=True)  # Reset index to include Timestamp again\n",
    "    df.dropna(inplace=True)  # Optional: drop rows with NaNs from rolling\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf62e2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_random_forest_with_grid_search(df, target_column, test_size=0.2, random_state=42, cv=5):\n",
    "    df = add_rolling_features(df)\n",
    "\n",
    "    X = df.drop(columns=[target_column, 'Timestamp', 'Service'])  # Drop non-numeric/time/grouping columns\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Keep only numeric features\n",
    "    X = X.select_dtypes(include=['number'])\n",
    "\n",
    "    # Define pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('rf', RandomForestRegressor(random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    # Grid search parameters\n",
    "    param_grid = {\n",
    "        'rf__max_depth': [3, 5, 10],\n",
    "        'rf__min_samples_split': [2, 5, 10],\n",
    "        'rf__min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    # Grid search\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        scoring='r2',\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)\n",
    "    best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = best_pipeline.predict(X_train)\n",
    "    y_test_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "    train_score = r2_score(y_train, y_train_pred)\n",
    "    test_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    return {\n",
    "        \"best_params\": best_params,\n",
    "        \"cv_best_score\": grid_search.best_score_,\n",
    "        \"train_score\": train_score,\n",
    "        \"test_score\": test_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91bcfdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test size: 0.3\n",
      "Service 1\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "CPU Usage R² Train - Service 1: 0.9999\n",
      "CPU Usage R² Test  - Service 1: 0.9986\n",
      "CPU Usage CV R² - Service 1: 0.9838\n",
      "Best Params - Service 1: {'rf__max_depth': 10, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5}\n",
      "Memory Usage R² Train - Service 1: 0.9515\n",
      "Memory Usage R² Test  - Service 1: 0.7815\n",
      "Memory Usage CV R² - Service 1: 0.8593\n",
      "Best Params - Service 1: {'rf__max_depth': 10, 'rf__min_samples_leaf': 4, 'rf__min_samples_split': 10}\n",
      "\n",
      "Service 2\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "CPU Usage R² Train - Service 2: 1.0000\n",
      "CPU Usage R² Test  - Service 2: 0.9996\n",
      "CPU Usage CV R² - Service 2: 0.9763\n",
      "Best Params - Service 2: {'rf__max_depth': 10, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 2}\n",
      "Memory Usage R² Train - Service 2: 0.9990\n",
      "Memory Usage R² Test  - Service 2: 0.9908\n",
      "Memory Usage CV R² - Service 2: 0.9931\n",
      "Best Params - Service 2: {'rf__max_depth': 10, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2}\n",
      "\n",
      "HashGen\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "CPU Usage R² Train - HashGen: 0.9999\n",
      "CPU Usage R² Test  - HashGen: 0.9943\n",
      "CPU Usage CV R² - HashGen: 0.9990\n",
      "Best Params - HashGen: {'rf__max_depth': 10, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2}\n",
      "Memory Usage R² Train - HashGen: 0.9985\n",
      "Memory Usage R² Test  - HashGen: 0.9817\n",
      "Memory Usage CV R² - HashGen: 0.9779\n",
      "Best Params - HashGen: {'rf__max_depth': 10, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 2}\n",
      "\n",
      "RandPw\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "CPU Usage R² Train - RandPw: 0.9989\n",
      "CPU Usage R² Test  - RandPw: 0.9849\n",
      "CPU Usage CV R² - RandPw: 0.9767\n",
      "Best Params - RandPw: {'rf__max_depth': 10, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 2}\n",
      "Memory Usage R² Train - RandPw: 0.9968\n",
      "Memory Usage R² Test  - RandPw: 0.7419\n",
      "Memory Usage CV R² - RandPw: 0.9166\n",
      "Best Params - RandPw: {'rf__max_depth': 10, 'rf__min_samples_leaf': 4, 'rf__min_samples_split': 10}\n",
      "\n",
      "\n",
      "Test size: 0.2\n",
      "Service 1\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "CPU Usage R² Train - Service 1: 0.9999\n",
      "CPU Usage R² Test  - Service 1: 0.9940\n",
      "CPU Usage CV R² - Service 1: 0.9838\n",
      "Best Params - Service 1: {'rf__max_depth': 10, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5}\n",
      "Memory Usage R² Train - Service 1: 0.9552\n",
      "Memory Usage R² Test  - Service 1: 0.7636\n",
      "Memory Usage CV R² - Service 1: 0.8593\n",
      "Best Params - Service 1: {'rf__max_depth': 10, 'rf__min_samples_leaf': 4, 'rf__min_samples_split': 10}\n",
      "\n",
      "Service 2\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "CPU Usage R² Train - Service 2: 1.0000\n",
      "CPU Usage R² Test  - Service 2: 0.9998\n",
      "CPU Usage CV R² - Service 2: 0.9763\n",
      "Best Params - Service 2: {'rf__max_depth': 10, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 2}\n",
      "Memory Usage R² Train - Service 2: 0.9991\n",
      "Memory Usage R² Test  - Service 2: 0.9932\n",
      "Memory Usage CV R² - Service 2: 0.9931\n",
      "Best Params - Service 2: {'rf__max_depth': 10, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2}\n",
      "\n",
      "HashGen\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "CPU Usage R² Train - HashGen: 0.9999\n",
      "CPU Usage R² Test  - HashGen: 0.9995\n",
      "CPU Usage CV R² - HashGen: 0.9990\n",
      "Best Params - HashGen: {'rf__max_depth': 10, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2}\n",
      "Memory Usage R² Train - HashGen: 0.9987\n",
      "Memory Usage R² Test  - HashGen: 0.9805\n",
      "Memory Usage CV R² - HashGen: 0.9779\n",
      "Best Params - HashGen: {'rf__max_depth': 10, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 2}\n",
      "\n",
      "RandPw\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "CPU Usage R² Train - RandPw: 0.9988\n",
      "CPU Usage R² Test  - RandPw: 0.9978\n",
      "CPU Usage CV R² - RandPw: 0.9767\n",
      "Best Params - RandPw: {'rf__max_depth': 10, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 2}\n",
      "Memory Usage R² Train - RandPw: 0.9969\n",
      "Memory Usage R² Test  - RandPw: 0.6811\n",
      "Memory Usage CV R² - RandPw: 0.9166\n",
      "Best Params - RandPw: {'rf__max_depth': 10, 'rf__min_samples_leaf': 4, 'rf__min_samples_split': 10}\n",
      "\n",
      "\n",
      "Test size: 0.1\n",
      "Service 1\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "CPU Usage R² Train - Service 1: 0.9999\n",
      "CPU Usage R² Test  - Service 1: 0.9871\n",
      "CPU Usage CV R² - Service 1: 0.9838\n",
      "Best Params - Service 1: {'rf__max_depth': 10, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 5}\n",
      "Memory Usage R² Train - Service 1: 0.9552\n",
      "Memory Usage R² Test  - Service 1: 0.7224\n",
      "Memory Usage CV R² - Service 1: 0.8593\n",
      "Best Params - Service 1: {'rf__max_depth': 10, 'rf__min_samples_leaf': 4, 'rf__min_samples_split': 10}\n",
      "\n",
      "Service 2\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "CPU Usage R² Train - Service 2: 1.0000\n",
      "CPU Usage R² Test  - Service 2: 0.9992\n",
      "CPU Usage CV R² - Service 2: 0.9763\n",
      "Best Params - Service 2: {'rf__max_depth': 10, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 2}\n",
      "Memory Usage R² Train - Service 2: 0.9992\n",
      "Memory Usage R² Test  - Service 2: 0.9967\n",
      "Memory Usage CV R² - Service 2: 0.9931\n",
      "Best Params - Service 2: {'rf__max_depth': 10, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2}\n",
      "\n",
      "HashGen\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "CPU Usage R² Train - HashGen: 0.9999\n",
      "CPU Usage R² Test  - HashGen: 0.9986\n",
      "CPU Usage CV R² - HashGen: 0.9990\n",
      "Best Params - HashGen: {'rf__max_depth': 10, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2}\n",
      "Memory Usage R² Train - HashGen: 0.9987\n",
      "Memory Usage R² Test  - HashGen: 0.9774\n",
      "Memory Usage CV R² - HashGen: 0.9779\n",
      "Best Params - HashGen: {'rf__max_depth': 10, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 2}\n",
      "\n",
      "RandPw\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "CPU Usage R² Train - RandPw: 0.9990\n",
      "CPU Usage R² Test  - RandPw: 0.9974\n",
      "CPU Usage CV R² - RandPw: 0.9767\n",
      "Best Params - RandPw: {'rf__max_depth': 10, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 2}\n",
      "Memory Usage R² Train - RandPw: 0.9973\n",
      "Memory Usage R² Test  - RandPw: 0.9937\n",
      "Memory Usage CV R² - RandPw: 0.9166\n",
      "Best Params - RandPw: {'rf__max_depth': 10, 'rf__min_samples_leaf': 4, 'rf__min_samples_split': 10}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sizes = [0.3, 0.2, 0.1]\n",
    "\n",
    "for test_size in test_sizes:\n",
    "    print(f\"\\nTest size: {test_size}\")\n",
    "    for label, df in configs.items():\n",
    "        print(label)\n",
    "        cpu_results = evaluate_random_forest_with_grid_search(df, 'CPU Usage', test_size)\n",
    "        mem_results = evaluate_random_forest_with_grid_search(df, 'Memory Usage', test_size)\n",
    "\n",
    "        print(f\"CPU Usage R² Train - {label}: {cpu_results['train_score']:.4f}\")\n",
    "        print(f\"CPU Usage R² Test  - {label}: {cpu_results['test_score']:.4f}\")\n",
    "        print(f\"CPU Usage CV R² - {label}: {cpu_results['cv_best_score']:.4f}\")\n",
    "        print(f\"Best Params - {label}: {cpu_results['best_params']}\")\n",
    "\n",
    "\n",
    "        print(f\"Memory Usage R² Train - {label}: {mem_results['train_score']:.4f}\")\n",
    "        print(f\"Memory Usage R² Test  - {label}: {mem_results['test_score']:.4f}\")\n",
    "        print(f\"Memory Usage CV R² - {label}: {mem_results['cv_best_score']:.4f}\")\n",
    "        print(f\"Best Params - {label}: {mem_results['best_params']}\")\n",
    "\n",
    "        print()  # Add a blank line between services for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13584d3f",
   "metadata": {},
   "source": [
    "Training with\n",
    "Test Size = 0.1\n",
    "Max Depth = 10\n",
    "Min Samples Leaf = 2\n",
    "Min Samples Split = 10\n",
    "{'max_depth': 10, 'min_samples_leaf':2, 'min_samples_split':2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5db84578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fixed_random_forest(df, target_column, test_size=0.1, random_state=42, cv=5):\n",
    "    df = add_rolling_features(df)\n",
    "\n",
    "    X = df.drop(columns=[target_column, 'Timestamp', 'Service'], errors='ignore')\n",
    "    y = df[target_column]\n",
    "    X = X.select_dtypes(include=['number'])\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('rf', RandomForestRegressor(\n",
    "            max_depth=10,\n",
    "            min_samples_leaf=2,\n",
    "            min_samples_split=2,\n",
    "            random_state=random_state\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    # Cross-validation (before train-test split)\n",
    "    cv_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='r2', n_jobs=-1)\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions and R²\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "    train_score = r2_score(y_train, y_train_pred)\n",
    "    test_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    return {\n",
    "        \"pipeline\": pipeline,\n",
    "        \"train_score\": train_score,\n",
    "        \"test_score\": test_score,\n",
    "        \"cv_mean_score\": cv_mean,\n",
    "        \"cv_std_score\": cv_std\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b75b2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service 1\n",
      "CPU Usage R² Train - Service 1: 0.9999\n",
      "CPU Usage R² Test  - Service 1: 0.9874\n",
      "CPU Usage CV Mean R² - Service 1: 0.9835 ± 0.0175\n",
      "Memory Usage R² Train - Service 1: 0.9782\n",
      "Memory Usage R² Test  - Service 1: 0.7503\n",
      "Memory Usage CV Mean R² - Service 1: 0.8474 ± 0.1926\n",
      "\n",
      "Service 2\n",
      "CPU Usage R² Train - Service 2: 1.0000\n",
      "CPU Usage R² Test  - Service 2: 0.9992\n",
      "CPU Usage CV Mean R² - Service 2: 0.9763 ± 0.0461\n",
      "Memory Usage R² Train - Service 2: 0.9988\n",
      "Memory Usage R² Test  - Service 2: 0.9961\n",
      "Memory Usage CV Mean R² - Service 2: 0.9930 ± 0.0037\n",
      "\n",
      "HashGen\n",
      "CPU Usage R² Train - HashGen: 0.9999\n",
      "CPU Usage R² Test  - HashGen: 0.9987\n",
      "CPU Usage CV Mean R² - HashGen: 0.9990 ± 0.0003\n",
      "Memory Usage R² Train - HashGen: 0.9987\n",
      "Memory Usage R² Test  - HashGen: 0.9774\n",
      "Memory Usage CV Mean R² - HashGen: 0.9779 ± 0.0167\n",
      "\n",
      "RandPw\n",
      "CPU Usage R² Train - RandPw: 0.9990\n",
      "CPU Usage R² Test  - RandPw: 0.9974\n",
      "CPU Usage CV Mean R² - RandPw: 0.9767 ± 0.0333\n",
      "Memory Usage R² Train - RandPw: 0.9986\n",
      "Memory Usage R² Test  - RandPw: 0.9907\n",
      "Memory Usage CV Mean R² - RandPw: 0.9049 ± 0.1308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label, df in configs.items():\n",
    "    print(label)\n",
    "    cpu_results = train_fixed_random_forest(df, 'CPU Usage', 0.1)\n",
    "    mem_results = train_fixed_random_forest(df, 'Memory Usage', 0.1)\n",
    "\n",
    "    print(f\"CPU Usage R² Train - {label}: {cpu_results['train_score']:.4f}\")\n",
    "    print(f\"CPU Usage R² Test  - {label}: {cpu_results['test_score']:.4f}\")\n",
    "    print(f\"CPU Usage CV Mean R² - {label}: {cpu_results['cv_mean_score']:.4f} ± {cpu_results['cv_std_score']:.4f}\")\n",
    "\n",
    "    print(f\"Memory Usage R² Train - {label}: {mem_results['train_score']:.4f}\")\n",
    "    print(f\"Memory Usage R² Test  - {label}: {mem_results['test_score']:.4f}\")\n",
    "    print(f\"Memory Usage CV Mean R² - {label}: {mem_results['cv_mean_score']:.4f} ± {mem_results['cv_std_score']:.4f}\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
