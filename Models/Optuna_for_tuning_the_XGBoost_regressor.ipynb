{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB2K61bb42KD",
        "outputId": "9be95dfc-dfc7-4910-8b44-581f7bcf8ca2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Service 1"
      ],
      "metadata": {
        "id": "dvnTcx5Y5rOR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12LelU6A4TaB",
        "outputId": "cd79959b-0b7e-4a02-e353-27b335edc742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-05 07:46:29,554] A new study created in memory with name: no-name-7eab056c-64ec-48c2-9363-75c19ee3dd00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 7000\n",
            "Validation set size: 1500\n",
            "Test set size: 1500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-05 07:46:30,477] Trial 0 finished with value: 0.011159097775816917 and parameters: {'n_estimators': 360, 'max_depth': 7, 'learning_rate': 0.10025836706344864, 'subsample': 0.855654903506101, 'colsample_bytree': 0.7680487763553826}. Best is trial 0 with value: 0.011159097775816917.\n",
            "[I 2025-05-05 07:46:34,430] Trial 1 finished with value: 0.012106318026781082 and parameters: {'n_estimators': 380, 'max_depth': 10, 'learning_rate': 0.05143624771147402, 'subsample': 0.7897656843036991, 'colsample_bytree': 0.8653594971197125}. Best is trial 0 with value: 0.011159097775816917.\n",
            "[I 2025-05-05 07:46:39,052] Trial 2 finished with value: 0.01444062776863575 and parameters: {'n_estimators': 353, 'max_depth': 10, 'learning_rate': 0.2077432258242544, 'subsample': 0.7788024989252733, 'colsample_bytree': 0.8412386295049843}. Best is trial 0 with value: 0.011159097775816917.\n",
            "[I 2025-05-05 07:46:39,404] Trial 3 finished with value: 0.010905393399298191 and parameters: {'n_estimators': 138, 'max_depth': 6, 'learning_rate': 0.18324462402025993, 'subsample': 0.7317417315442848, 'colsample_bytree': 0.8955022247418218}. Best is trial 3 with value: 0.010905393399298191.\n",
            "[I 2025-05-05 07:46:40,121] Trial 4 finished with value: 0.011428329162299633 and parameters: {'n_estimators': 181, 'max_depth': 9, 'learning_rate': 0.1078854627695962, 'subsample': 0.8840110390852063, 'colsample_bytree': 0.7156873951371636}. Best is trial 3 with value: 0.010905393399298191.\n",
            "[I 2025-05-05 07:46:40,592] Trial 5 finished with value: 0.012531270273029804 and parameters: {'n_estimators': 409, 'max_depth': 3, 'learning_rate': 0.06904979553004262, 'subsample': 0.8204173299986102, 'colsample_bytree': 0.9416893378533298}. Best is trial 3 with value: 0.010905393399298191.\n",
            "[I 2025-05-05 07:46:41,800] Trial 6 finished with value: 0.009922981262207031 and parameters: {'n_estimators': 223, 'max_depth': 10, 'learning_rate': 0.036824239308269294, 'subsample': 0.9416026776437002, 'colsample_bytree': 0.9245081701297952}. Best is trial 6 with value: 0.009922981262207031.\n",
            "[I 2025-05-05 07:46:43,432] Trial 7 finished with value: 0.014097191393375397 and parameters: {'n_estimators': 224, 'max_depth': 10, 'learning_rate': 0.1805678327991276, 'subsample': 0.9037447586838924, 'colsample_bytree': 0.9150995389192986}. Best is trial 6 with value: 0.009922981262207031.\n",
            "[I 2025-05-05 07:46:45,456] Trial 8 finished with value: 0.012619683519005775 and parameters: {'n_estimators': 303, 'max_depth': 10, 'learning_rate': 0.08159220866659149, 'subsample': 0.8382879104263324, 'colsample_bytree': 0.8682368631436352}. Best is trial 6 with value: 0.009922981262207031.\n",
            "[I 2025-05-05 07:46:46,158] Trial 9 finished with value: 0.010219566524028778 and parameters: {'n_estimators': 357, 'max_depth': 6, 'learning_rate': 0.0778295383367836, 'subsample': 0.8007506752745457, 'colsample_bytree': 0.7992864050358411}. Best is trial 6 with value: 0.009922981262207031.\n",
            "[I 2025-05-05 07:46:49,540] Trial 10 finished with value: 0.013829033821821213 and parameters: {'n_estimators': 489, 'max_depth': 8, 'learning_rate': 0.2992341875468875, 'subsample': 0.9924886427115632, 'colsample_bytree': 0.9818868892405516}. Best is trial 6 with value: 0.009922981262207031.\n",
            "[I 2025-05-05 07:46:50,403] Trial 11 finished with value: 0.009937657043337822 and parameters: {'n_estimators': 237, 'max_depth': 5, 'learning_rate': 0.027909014130278853, 'subsample': 0.9580025696289867, 'colsample_bytree': 0.7918220255235812}. Best is trial 6 with value: 0.009922981262207031.\n",
            "[I 2025-05-05 07:46:50,818] Trial 12 finished with value: 0.012293579988181591 and parameters: {'n_estimators': 243, 'max_depth': 4, 'learning_rate': 0.025340294166519416, 'subsample': 0.966278550130343, 'colsample_bytree': 0.8020041273366649}. Best is trial 6 with value: 0.009922981262207031.\n",
            "[I 2025-05-05 07:46:51,325] Trial 13 finished with value: 3.041076183319092 and parameters: {'n_estimators': 256, 'max_depth': 5, 'learning_rate': 0.01129137004586785, 'subsample': 0.936903385240763, 'colsample_bytree': 0.9992723219553579}. Best is trial 6 with value: 0.009922981262207031.\n",
            "[I 2025-05-05 07:46:51,757] Trial 14 finished with value: 0.010753176175057888 and parameters: {'n_estimators': 124, 'max_depth': 8, 'learning_rate': 0.14100394963128354, 'subsample': 0.9429864024333339, 'colsample_bytree': 0.711640785867296}. Best is trial 6 with value: 0.009922981262207031.\n",
            "[I 2025-05-05 07:46:52,303] Trial 15 finished with value: 0.008753668516874313 and parameters: {'n_estimators': 286, 'max_depth': 5, 'learning_rate': 0.04240863170733056, 'subsample': 0.9874681227091663, 'colsample_bytree': 0.9505032064375454}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:52,633] Trial 16 finished with value: 0.016225498169660568 and parameters: {'n_estimators': 298, 'max_depth': 3, 'learning_rate': 0.1336093759507316, 'subsample': 0.9907402691350149, 'colsample_bytree': 0.9558817218669489}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:53,213] Trial 17 finished with value: 0.012265879660844803 and parameters: {'n_estimators': 180, 'max_depth': 7, 'learning_rate': 0.24769663045489193, 'subsample': 0.9037125335298108, 'colsample_bytree': 0.92550787861956}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:53,823] Trial 18 finished with value: 0.009064989164471626 and parameters: {'n_estimators': 317, 'max_depth': 5, 'learning_rate': 0.04824600966581838, 'subsample': 0.9186682054004187, 'colsample_bytree': 0.965144848726186}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:54,613] Trial 19 finished with value: 0.010567924939095974 and parameters: {'n_estimators': 456, 'max_depth': 5, 'learning_rate': 0.10751349811337998, 'subsample': 0.9034227989372909, 'colsample_bytree': 0.9689297410078681}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:55,075] Trial 20 finished with value: 0.008814869448542595 and parameters: {'n_estimators': 301, 'max_depth': 4, 'learning_rate': 0.05334785544264345, 'subsample': 0.9951222884600449, 'colsample_bytree': 0.9949006764211643}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:55,528] Trial 21 finished with value: 0.008929643779993057 and parameters: {'n_estimators': 308, 'max_depth': 4, 'learning_rate': 0.0579044307792181, 'subsample': 0.996429753464733, 'colsample_bytree': 0.9995370761112993}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:55,956] Trial 22 finished with value: 0.009074702858924866 and parameters: {'n_estimators': 275, 'max_depth': 4, 'learning_rate': 0.060807698183237335, 'subsample': 0.9971879127999425, 'colsample_bytree': 0.9976635630947307}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:56,457] Trial 23 finished with value: 0.8219555616378784 and parameters: {'n_estimators': 321, 'max_depth': 4, 'learning_rate': 0.011056622776825661, 'subsample': 0.963619149341193, 'colsample_bytree': 0.9487140002878359}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:57,046] Trial 24 finished with value: 0.00998010579496622 and parameters: {'n_estimators': 409, 'max_depth': 4, 'learning_rate': 0.09091257255726114, 'subsample': 0.9751653784215002, 'colsample_bytree': 0.9897273291955275}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:57,397] Trial 25 finished with value: 0.0163070410490036 and parameters: {'n_estimators': 283, 'max_depth': 3, 'learning_rate': 0.11699023227909956, 'subsample': 0.9759764983808693, 'colsample_bytree': 0.8904757148002135}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:57,888] Trial 26 finished with value: 0.008831503801047802 and parameters: {'n_estimators': 194, 'max_depth': 6, 'learning_rate': 0.04808819226826041, 'subsample': 0.9998864418797404, 'colsample_bytree': 0.970662567595514}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:58,380] Trial 27 finished with value: 0.008845396339893341 and parameters: {'n_estimators': 183, 'max_depth': 6, 'learning_rate': 0.04531158006175998, 'subsample': 0.9293998898717505, 'colsample_bytree': 0.9725328809607912}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:58,830] Trial 28 finished with value: 0.010612311773002148 and parameters: {'n_estimators': 152, 'max_depth': 7, 'learning_rate': 0.16740061872367037, 'subsample': 0.9539938966389627, 'colsample_bytree': 0.9434557648386965}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:59,384] Trial 29 finished with value: 0.01005902886390686 and parameters: {'n_estimators': 207, 'max_depth': 6, 'learning_rate': 0.08998580560604441, 'subsample': 0.8599270889921625, 'colsample_bytree': 0.8338981046721313}. Best is trial 15 with value: 0.008753668516874313.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters from Optuna: {'n_estimators': 286, 'max_depth': 5, 'learning_rate': 0.04240863170733056, 'subsample': 0.9874681227091663, 'colsample_bytree': 0.9505032064375454}\n",
            "\n",
            "Test MSE: 0.0077\n",
            "Test RMSE: 0.0880\n",
            "\n",
            "Sample Input Prediction (CPU, Memory): [79.64726  31.038286]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import optuna\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"Service1.csv\")\n",
        "\n",
        "# Define input features and output targets\n",
        "X = df[['latency_ms', 'cpu_allocated', 'memory_allocated', 'cpu_usage_pct', 'memory_usage_pct']]\n",
        "y = df[['cpu_usage_pct', 'memory_usage_pct']]\n",
        "\n",
        "# Split into train (70%), validation (15%), test (15%)\n",
        "X_train_full, X_temp, y_train_full, y_temp = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42)\n",
        "\n",
        "print(f\"Train set size: {len(X_train_full)}\")\n",
        "print(f\"Validation set size: {len(X_val)}\")\n",
        "print(f\"Test set size: {len(X_test)}\")\n",
        "\n",
        "# Define Optuna objective function\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
        "    }\n",
        "    model = MultiOutputRegressor(XGBRegressor(**params, random_state=42, verbosity=0))\n",
        "    model.fit(X_train_full, y_train_full)\n",
        "    preds = model.predict(X_val)\n",
        "    return mean_squared_error(y_val, preds)\n",
        "\n",
        "# Run Optuna optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=30)\n",
        "print(\"Best Parameters from Optuna:\", study.best_params)\n",
        "\n",
        "# Train final model on train + validation sets\n",
        "X_train_combined = pd.concat([X_train_full, X_val])\n",
        "y_train_combined = pd.concat([y_train_full, y_val])\n",
        "\n",
        "best_params = study.best_params\n",
        "final_model = MultiOutputRegressor(XGBRegressor(**best_params, random_state=42))\n",
        "final_model.fit(X_train_combined, y_train_combined)\n",
        "\n",
        "# Evaluate on test set\n",
        "predictions = final_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"\\nTest MSE: {mse:.4f}\")\n",
        "print(f\"Test RMSE: {rmse:.4f}\")\n",
        "\n",
        "# Predict on a new sample (optional)\n",
        "sample_input = pd.DataFrame([[300,0.25,512, 45, 60]], columns=['latency_ms', 'cpu_allocated', 'memory_allocated', 'cpu_usage_pct', 'memory_usage_pct'])\n",
        "predicted_allocation = final_model.predict(sample_input)\n",
        "print(f\"\\nSample Input Prediction (CPU, Memory): {predicted_allocation[0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Service 2"
      ],
      "metadata": {
        "id": "28Tn0oXt5uwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import optuna\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"Service2.csv\")\n",
        "\n",
        "# Define input features and output targets\n",
        "X = df[['latency_ms', 'cpu_allocated', 'memory_allocated', 'cpu_usage_pct', 'memory_usage_pct']]\n",
        "y = df[['cpu_allocated', 'memory_allocated']]\n",
        "\n",
        "# Split into train (70%), validation (15%), test (15%)\n",
        "X_train_full, X_temp, y_train_full, y_temp = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42)\n",
        "\n",
        "print(f\"Train set size: {len(X_train_full)}\")\n",
        "print(f\"Validation set size: {len(X_val)}\")\n",
        "print(f\"Test set size: {len(X_test)}\")\n",
        "\n",
        "# Define Optuna objective function\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
        "    }\n",
        "    model = MultiOutputRegressor(XGBRegressor(**params, random_state=42, verbosity=0))\n",
        "    model.fit(X_train_full, y_train_full)\n",
        "    preds = model.predict(X_val)\n",
        "    return mean_squared_error(y_val, preds)\n",
        "\n",
        "# Run Optuna optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=30)\n",
        "print(\"Best Parameters from Optuna:\", study.best_params)\n",
        "\n",
        "# Train final model on train + validation sets\n",
        "X_train_combined = pd.concat([X_train_full, X_val])\n",
        "y_train_combined = pd.concat([y_train_full, y_val])\n",
        "\n",
        "best_params = study.best_params\n",
        "final_model = MultiOutputRegressor(XGBRegressor(**best_params, random_state=42))\n",
        "final_model.fit(X_train_combined, y_train_combined)\n",
        "\n",
        "# Evaluate on test set\n",
        "predictions = final_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"\\nTest MSE: {mse:.4f}\")\n",
        "print(f\"Test RMSE: {rmse:.4f}\")\n",
        "\n",
        "# Predict on a new sample (optional)\n",
        "sample_input = pd.DataFrame([[300,0.25, 500, 45, 60]], columns=['latency_ms', 'cpu_allocated', 'memory_allocated', 'cpu_usage_pct', 'memory_usage_pct'])\n",
        "predicted_allocation = final_model.predict(sample_input)\n",
        "print(f\"\\nSample Input Prediction (CPU, Memory): {predicted_allocation[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XP57zz55ws6",
        "outputId": "11962988-38bd-4bc7-a599-3911fd7804ef"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-05 08:05:42,426] A new study created in memory with name: no-name-ec6c209a-81a0-49f5-811b-0c6edbb455e7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 7000\n",
            "Validation set size: 1500\n",
            "Test set size: 1500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-05 08:05:42,955] Trial 0 finished with value: 1.0692851543426514 and parameters: {'n_estimators': 405, 'max_depth': 5, 'learning_rate': 0.16047019899306242, 'subsample': 0.746845180620814, 'colsample_bytree': 0.8802228716741932}. Best is trial 0 with value: 1.0692851543426514.\n",
            "[I 2025-05-05 08:05:43,392] Trial 1 finished with value: 0.9658798575401306 and parameters: {'n_estimators': 166, 'max_depth': 8, 'learning_rate': 0.12659433073193643, 'subsample': 0.8172612061260072, 'colsample_bytree': 0.9700480650586986}. Best is trial 1 with value: 0.9658798575401306.\n",
            "[I 2025-05-05 08:05:43,853] Trial 2 finished with value: 1.2115553617477417 and parameters: {'n_estimators': 410, 'max_depth': 4, 'learning_rate': 0.23022813670049627, 'subsample': 0.8835620205487946, 'colsample_bytree': 0.9285258391465312}. Best is trial 1 with value: 0.9658798575401306.\n",
            "[I 2025-05-05 08:05:45,171] Trial 3 finished with value: 1.0734285116195679 and parameters: {'n_estimators': 436, 'max_depth': 9, 'learning_rate': 0.1039017357922787, 'subsample': 0.8378250377636779, 'colsample_bytree': 0.8018279021187696}. Best is trial 1 with value: 0.9658798575401306.\n",
            "[I 2025-05-05 08:05:45,454] Trial 4 finished with value: 3.7282629013061523 and parameters: {'n_estimators': 282, 'max_depth': 3, 'learning_rate': 0.17824623452881191, 'subsample': 0.9533079701087851, 'colsample_bytree': 0.7835914907956907}. Best is trial 1 with value: 0.9658798575401306.\n",
            "[I 2025-05-05 08:05:45,923] Trial 5 finished with value: 1.2405349016189575 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.21962158414676933, 'subsample': 0.9759319104141573, 'colsample_bytree': 0.8568686472261591}. Best is trial 1 with value: 0.9658798575401306.\n",
            "[I 2025-05-05 08:05:47,585] Trial 6 finished with value: 0.9883649945259094 and parameters: {'n_estimators': 245, 'max_depth': 5, 'learning_rate': 0.07903961777450867, 'subsample': 0.7930908207488764, 'colsample_bytree': 0.9085919010693686}. Best is trial 1 with value: 0.9658798575401306.\n",
            "[I 2025-05-05 08:05:48,911] Trial 7 finished with value: 1.1592636108398438 and parameters: {'n_estimators': 367, 'max_depth': 8, 'learning_rate': 0.1970968550980395, 'subsample': 0.7028868220480069, 'colsample_bytree': 0.7460739602455305}. Best is trial 1 with value: 0.9658798575401306.\n",
            "[I 2025-05-05 08:05:49,331] Trial 8 finished with value: 0.9815157055854797 and parameters: {'n_estimators': 238, 'max_depth': 6, 'learning_rate': 0.0969916357394363, 'subsample': 0.9644623998190494, 'colsample_bytree': 0.9892838525188987}. Best is trial 1 with value: 0.9658798575401306.\n",
            "[I 2025-05-05 08:05:49,961] Trial 9 finished with value: 1.0886178016662598 and parameters: {'n_estimators': 278, 'max_depth': 8, 'learning_rate': 0.21964653388694366, 'subsample': 0.9485585073397785, 'colsample_bytree': 0.8559465634948533}. Best is trial 1 with value: 0.9658798575401306.\n",
            "[I 2025-05-05 08:05:50,393] Trial 10 finished with value: 1968.1451416015625 and parameters: {'n_estimators': 122, 'max_depth': 10, 'learning_rate': 0.0172610068424595, 'subsample': 0.8635071319545766, 'colsample_bytree': 0.9918536371911373}. Best is trial 1 with value: 0.9658798575401306.\n",
            "[I 2025-05-05 08:05:50,821] Trial 11 finished with value: 0.9729889631271362 and parameters: {'n_estimators': 187, 'max_depth': 6, 'learning_rate': 0.08760871814198523, 'subsample': 0.806234287814367, 'colsample_bytree': 0.9918926115581747}. Best is trial 1 with value: 0.9658798575401306.\n",
            "[I 2025-05-05 08:05:51,187] Trial 12 finished with value: 1.1067744493484497 and parameters: {'n_estimators': 173, 'max_depth': 7, 'learning_rate': 0.28725739989998345, 'subsample': 0.8031644219416683, 'colsample_bytree': 0.9524305616672392}. Best is trial 1 with value: 0.9658798575401306.\n",
            "[I 2025-05-05 08:05:51,667] Trial 13 finished with value: 0.8630320429801941 and parameters: {'n_estimators': 181, 'max_depth': 6, 'learning_rate': 0.044781610435067586, 'subsample': 0.7972853778174079, 'colsample_bytree': 0.9586248863584473}. Best is trial 13 with value: 0.8630320429801941.\n",
            "[I 2025-05-05 08:05:52,289] Trial 14 finished with value: 260.6708679199219 and parameters: {'n_estimators': 178, 'max_depth': 8, 'learning_rate': 0.017500755862978456, 'subsample': 0.9082719096666303, 'colsample_bytree': 0.9463439866903582}. Best is trial 13 with value: 0.8630320429801941.\n",
            "[I 2025-05-05 08:05:53,791] Trial 15 finished with value: 0.9378756284713745 and parameters: {'n_estimators': 352, 'max_depth': 10, 'learning_rate': 0.05024295904926978, 'subsample': 0.7555326441158712, 'colsample_bytree': 0.9120409766053698}. Best is trial 13 with value: 0.8630320429801941.\n",
            "[I 2025-05-05 08:05:55,899] Trial 16 finished with value: 0.9910368323326111 and parameters: {'n_estimators': 495, 'max_depth': 10, 'learning_rate': 0.05098802683643468, 'subsample': 0.7530590659024864, 'colsample_bytree': 0.902538863758973}. Best is trial 13 with value: 0.8630320429801941.\n",
            "[I 2025-05-05 08:05:56,471] Trial 17 finished with value: 0.8653791546821594 and parameters: {'n_estimators': 325, 'max_depth': 5, 'learning_rate': 0.05160711727160245, 'subsample': 0.7626683828617142, 'colsample_bytree': 0.8228870696956516}. Best is trial 13 with value: 0.8630320429801941.\n",
            "[I 2025-05-05 08:05:56,935] Trial 18 finished with value: 0.9482035636901855 and parameters: {'n_estimators': 348, 'max_depth': 4, 'learning_rate': 0.05005530640903768, 'subsample': 0.7146633833357632, 'colsample_bytree': 0.8148883200547409}. Best is trial 13 with value: 0.8630320429801941.\n",
            "[I 2025-05-05 08:05:57,385] Trial 19 finished with value: 1.1647950410842896 and parameters: {'n_estimators': 312, 'max_depth': 5, 'learning_rate': 0.13017013868583438, 'subsample': 0.7790320874059926, 'colsample_bytree': 0.7215654209229091}. Best is trial 13 with value: 0.8630320429801941.\n",
            "[I 2025-05-05 08:05:57,655] Trial 20 finished with value: 3.235949754714966 and parameters: {'n_estimators': 224, 'max_depth': 3, 'learning_rate': 0.06595527198423011, 'subsample': 0.8371542011565536, 'colsample_bytree': 0.7646987446764029}. Best is trial 13 with value: 0.8630320429801941.\n",
            "[I 2025-05-05 08:05:58,419] Trial 21 finished with value: 0.8284994959831238 and parameters: {'n_estimators': 330, 'max_depth': 6, 'learning_rate': 0.039988168496775216, 'subsample': 0.7513683268438961, 'colsample_bytree': 0.8255147845220253}. Best is trial 21 with value: 0.8284994959831238.\n",
            "[I 2025-05-05 08:06:01,217] Trial 22 finished with value: 16.10649299621582 and parameters: {'n_estimators': 313, 'max_depth': 6, 'learning_rate': 0.014521062110859576, 'subsample': 0.7325698859634897, 'colsample_bytree': 0.8148739416144588}. Best is trial 21 with value: 0.8284994959831238.\n",
            "[I 2025-05-05 08:06:01,711] Trial 23 finished with value: 0.899907112121582 and parameters: {'n_estimators': 327, 'max_depth': 4, 'learning_rate': 0.04116178962493022, 'subsample': 0.770472739749388, 'colsample_bytree': 0.8351935593611755}. Best is trial 21 with value: 0.8284994959831238.\n",
            "[I 2025-05-05 08:06:02,129] Trial 24 finished with value: 1.0686661005020142 and parameters: {'n_estimators': 274, 'max_depth': 5, 'learning_rate': 0.12212160913296972, 'subsample': 0.7277650686983557, 'colsample_bytree': 0.8690931193090473}. Best is trial 21 with value: 0.8284994959831238.\n",
            "[I 2025-05-05 08:06:03,116] Trial 25 finished with value: 0.8264708518981934 and parameters: {'n_estimators': 386, 'max_depth': 7, 'learning_rate': 0.034101179023035666, 'subsample': 0.7763505739488309, 'colsample_bytree': 0.8403506356042817}. Best is trial 25 with value: 0.8264708518981934.\n",
            "[I 2025-05-05 08:06:04,273] Trial 26 finished with value: 0.8246095776557922 and parameters: {'n_estimators': 472, 'max_depth': 7, 'learning_rate': 0.0310705349569793, 'subsample': 0.7836958427890012, 'colsample_bytree': 0.8852147638239811}. Best is trial 26 with value: 0.8246095776557922.\n",
            "[I 2025-05-05 08:06:05,419] Trial 27 finished with value: 0.8170772194862366 and parameters: {'n_estimators': 465, 'max_depth': 7, 'learning_rate': 0.029464046555470448, 'subsample': 0.8272020582423519, 'colsample_bytree': 0.8880107644386758}. Best is trial 27 with value: 0.8170772194862366.\n",
            "[I 2025-05-05 08:06:06,406] Trial 28 finished with value: 0.9181348085403442 and parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.07240478533225501, 'subsample': 0.8694893849013002, 'colsample_bytree': 0.8912698448779369}. Best is trial 27 with value: 0.8170772194862366.\n",
            "[I 2025-05-05 08:06:07,960] Trial 29 finished with value: 1.1443876028060913 and parameters: {'n_estimators': 459, 'max_depth': 9, 'learning_rate': 0.15130078369888178, 'subsample': 0.8294427168634483, 'colsample_bytree': 0.8676644288821658}. Best is trial 27 with value: 0.8170772194862366.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters from Optuna: {'n_estimators': 465, 'max_depth': 7, 'learning_rate': 0.029464046555470448, 'subsample': 0.8272020582423519, 'colsample_bytree': 0.8880107644386758}\n",
            "\n",
            "Test MSE: 0.7573\n",
            "Test RMSE: 0.8702\n",
            "\n",
            "Sample Input Prediction (CPU, Memory): [2.7600870e-01 7.4864545e+02]\n"
          ]
        }
      ]
    }
  ]
}