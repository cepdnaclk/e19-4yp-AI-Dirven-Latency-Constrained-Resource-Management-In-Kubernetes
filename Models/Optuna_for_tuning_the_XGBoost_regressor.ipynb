{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB2K61bb42KD",
        "outputId": "de635cad-8b3e-48ff-b6e4-5cf0bec5b021"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.1)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Service 1"
      ],
      "metadata": {
        "id": "dvnTcx5Y5rOR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12LelU6A4TaB",
        "outputId": "cd79959b-0b7e-4a02-e353-27b335edc742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-05 07:46:29,554] A new study created in memory with name: no-name-7eab056c-64ec-48c2-9363-75c19ee3dd00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 7000\n",
            "Validation set size: 1500\n",
            "Test set size: 1500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-05 07:46:30,477] Trial 0 finished with value: 0.011159097775816917 and parameters: {'n_estimators': 360, 'max_depth': 7, 'learning_rate': 0.10025836706344864, 'subsample': 0.855654903506101, 'colsample_bytree': 0.7680487763553826}. Best is trial 0 with value: 0.011159097775816917.\n",
            "[I 2025-05-05 07:46:34,430] Trial 1 finished with value: 0.012106318026781082 and parameters: {'n_estimators': 380, 'max_depth': 10, 'learning_rate': 0.05143624771147402, 'subsample': 0.7897656843036991, 'colsample_bytree': 0.8653594971197125}. Best is trial 0 with value: 0.011159097775816917.\n",
            "[I 2025-05-05 07:46:39,052] Trial 2 finished with value: 0.01444062776863575 and parameters: {'n_estimators': 353, 'max_depth': 10, 'learning_rate': 0.2077432258242544, 'subsample': 0.7788024989252733, 'colsample_bytree': 0.8412386295049843}. Best is trial 0 with value: 0.011159097775816917.\n",
            "[I 2025-05-05 07:46:39,404] Trial 3 finished with value: 0.010905393399298191 and parameters: {'n_estimators': 138, 'max_depth': 6, 'learning_rate': 0.18324462402025993, 'subsample': 0.7317417315442848, 'colsample_bytree': 0.8955022247418218}. Best is trial 3 with value: 0.010905393399298191.\n",
            "[I 2025-05-05 07:46:40,121] Trial 4 finished with value: 0.011428329162299633 and parameters: {'n_estimators': 181, 'max_depth': 9, 'learning_rate': 0.1078854627695962, 'subsample': 0.8840110390852063, 'colsample_bytree': 0.7156873951371636}. Best is trial 3 with value: 0.010905393399298191.\n",
            "[I 2025-05-05 07:46:40,592] Trial 5 finished with value: 0.012531270273029804 and parameters: {'n_estimators': 409, 'max_depth': 3, 'learning_rate': 0.06904979553004262, 'subsample': 0.8204173299986102, 'colsample_bytree': 0.9416893378533298}. Best is trial 3 with value: 0.010905393399298191.\n",
            "[I 2025-05-05 07:46:41,800] Trial 6 finished with value: 0.009922981262207031 and parameters: {'n_estimators': 223, 'max_depth': 10, 'learning_rate': 0.036824239308269294, 'subsample': 0.9416026776437002, 'colsample_bytree': 0.9245081701297952}. Best is trial 6 with value: 0.009922981262207031.\n",
            "[I 2025-05-05 07:46:43,432] Trial 7 finished with value: 0.014097191393375397 and parameters: {'n_estimators': 224, 'max_depth': 10, 'learning_rate': 0.1805678327991276, 'subsample': 0.9037447586838924, 'colsample_bytree': 0.9150995389192986}. Best is trial 6 with value: 0.009922981262207031.\n",
            "[I 2025-05-05 07:46:45,456] Trial 8 finished with value: 0.012619683519005775 and parameters: {'n_estimators': 303, 'max_depth': 10, 'learning_rate': 0.08159220866659149, 'subsample': 0.8382879104263324, 'colsample_bytree': 0.8682368631436352}. Best is trial 6 with value: 0.009922981262207031.\n",
            "[I 2025-05-05 07:46:46,158] Trial 9 finished with value: 0.010219566524028778 and parameters: {'n_estimators': 357, 'max_depth': 6, 'learning_rate': 0.0778295383367836, 'subsample': 0.8007506752745457, 'colsample_bytree': 0.7992864050358411}. Best is trial 6 with value: 0.009922981262207031.\n",
            "[I 2025-05-05 07:46:49,540] Trial 10 finished with value: 0.013829033821821213 and parameters: {'n_estimators': 489, 'max_depth': 8, 'learning_rate': 0.2992341875468875, 'subsample': 0.9924886427115632, 'colsample_bytree': 0.9818868892405516}. Best is trial 6 with value: 0.009922981262207031.\n",
            "[I 2025-05-05 07:46:50,403] Trial 11 finished with value: 0.009937657043337822 and parameters: {'n_estimators': 237, 'max_depth': 5, 'learning_rate': 0.027909014130278853, 'subsample': 0.9580025696289867, 'colsample_bytree': 0.7918220255235812}. Best is trial 6 with value: 0.009922981262207031.\n",
            "[I 2025-05-05 07:46:50,818] Trial 12 finished with value: 0.012293579988181591 and parameters: {'n_estimators': 243, 'max_depth': 4, 'learning_rate': 0.025340294166519416, 'subsample': 0.966278550130343, 'colsample_bytree': 0.8020041273366649}. Best is trial 6 with value: 0.009922981262207031.\n",
            "[I 2025-05-05 07:46:51,325] Trial 13 finished with value: 3.041076183319092 and parameters: {'n_estimators': 256, 'max_depth': 5, 'learning_rate': 0.01129137004586785, 'subsample': 0.936903385240763, 'colsample_bytree': 0.9992723219553579}. Best is trial 6 with value: 0.009922981262207031.\n",
            "[I 2025-05-05 07:46:51,757] Trial 14 finished with value: 0.010753176175057888 and parameters: {'n_estimators': 124, 'max_depth': 8, 'learning_rate': 0.14100394963128354, 'subsample': 0.9429864024333339, 'colsample_bytree': 0.711640785867296}. Best is trial 6 with value: 0.009922981262207031.\n",
            "[I 2025-05-05 07:46:52,303] Trial 15 finished with value: 0.008753668516874313 and parameters: {'n_estimators': 286, 'max_depth': 5, 'learning_rate': 0.04240863170733056, 'subsample': 0.9874681227091663, 'colsample_bytree': 0.9505032064375454}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:52,633] Trial 16 finished with value: 0.016225498169660568 and parameters: {'n_estimators': 298, 'max_depth': 3, 'learning_rate': 0.1336093759507316, 'subsample': 0.9907402691350149, 'colsample_bytree': 0.9558817218669489}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:53,213] Trial 17 finished with value: 0.012265879660844803 and parameters: {'n_estimators': 180, 'max_depth': 7, 'learning_rate': 0.24769663045489193, 'subsample': 0.9037125335298108, 'colsample_bytree': 0.92550787861956}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:53,823] Trial 18 finished with value: 0.009064989164471626 and parameters: {'n_estimators': 317, 'max_depth': 5, 'learning_rate': 0.04824600966581838, 'subsample': 0.9186682054004187, 'colsample_bytree': 0.965144848726186}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:54,613] Trial 19 finished with value: 0.010567924939095974 and parameters: {'n_estimators': 456, 'max_depth': 5, 'learning_rate': 0.10751349811337998, 'subsample': 0.9034227989372909, 'colsample_bytree': 0.9689297410078681}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:55,075] Trial 20 finished with value: 0.008814869448542595 and parameters: {'n_estimators': 301, 'max_depth': 4, 'learning_rate': 0.05334785544264345, 'subsample': 0.9951222884600449, 'colsample_bytree': 0.9949006764211643}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:55,528] Trial 21 finished with value: 0.008929643779993057 and parameters: {'n_estimators': 308, 'max_depth': 4, 'learning_rate': 0.0579044307792181, 'subsample': 0.996429753464733, 'colsample_bytree': 0.9995370761112993}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:55,956] Trial 22 finished with value: 0.009074702858924866 and parameters: {'n_estimators': 275, 'max_depth': 4, 'learning_rate': 0.060807698183237335, 'subsample': 0.9971879127999425, 'colsample_bytree': 0.9976635630947307}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:56,457] Trial 23 finished with value: 0.8219555616378784 and parameters: {'n_estimators': 321, 'max_depth': 4, 'learning_rate': 0.011056622776825661, 'subsample': 0.963619149341193, 'colsample_bytree': 0.9487140002878359}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:57,046] Trial 24 finished with value: 0.00998010579496622 and parameters: {'n_estimators': 409, 'max_depth': 4, 'learning_rate': 0.09091257255726114, 'subsample': 0.9751653784215002, 'colsample_bytree': 0.9897273291955275}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:57,397] Trial 25 finished with value: 0.0163070410490036 and parameters: {'n_estimators': 283, 'max_depth': 3, 'learning_rate': 0.11699023227909956, 'subsample': 0.9759764983808693, 'colsample_bytree': 0.8904757148002135}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:57,888] Trial 26 finished with value: 0.008831503801047802 and parameters: {'n_estimators': 194, 'max_depth': 6, 'learning_rate': 0.04808819226826041, 'subsample': 0.9998864418797404, 'colsample_bytree': 0.970662567595514}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:58,380] Trial 27 finished with value: 0.008845396339893341 and parameters: {'n_estimators': 183, 'max_depth': 6, 'learning_rate': 0.04531158006175998, 'subsample': 0.9293998898717505, 'colsample_bytree': 0.9725328809607912}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:58,830] Trial 28 finished with value: 0.010612311773002148 and parameters: {'n_estimators': 152, 'max_depth': 7, 'learning_rate': 0.16740061872367037, 'subsample': 0.9539938966389627, 'colsample_bytree': 0.9434557648386965}. Best is trial 15 with value: 0.008753668516874313.\n",
            "[I 2025-05-05 07:46:59,384] Trial 29 finished with value: 0.01005902886390686 and parameters: {'n_estimators': 207, 'max_depth': 6, 'learning_rate': 0.08998580560604441, 'subsample': 0.8599270889921625, 'colsample_bytree': 0.8338981046721313}. Best is trial 15 with value: 0.008753668516874313.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters from Optuna: {'n_estimators': 286, 'max_depth': 5, 'learning_rate': 0.04240863170733056, 'subsample': 0.9874681227091663, 'colsample_bytree': 0.9505032064375454}\n",
            "\n",
            "Test MSE: 0.0077\n",
            "Test RMSE: 0.0880\n",
            "\n",
            "Sample Input Prediction (CPU, Memory): [79.64726  31.038286]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import optuna\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"Service1.csv\")\n",
        "\n",
        "# Define input features and output targets\n",
        "X = df[['latency_ms', 'cpu_allocated', 'memory_allocated', 'cpu_usage_pct', 'memory_usage_pct']]\n",
        "y = df[['cpu_usage_pct', 'memory_usage_pct']]\n",
        "\n",
        "# Split into train (70%), validation (15%), test (15%)\n",
        "X_train_full, X_temp, y_train_full, y_temp = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42)\n",
        "\n",
        "print(f\"Train set size: {len(X_train_full)}\")\n",
        "print(f\"Validation set size: {len(X_val)}\")\n",
        "print(f\"Test set size: {len(X_test)}\")\n",
        "\n",
        "# Define Optuna objective function\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
        "    }\n",
        "    model = MultiOutputRegressor(XGBRegressor(**params, random_state=42, verbosity=0))\n",
        "    model.fit(X_train_full, y_train_full)\n",
        "    preds = model.predict(X_val)\n",
        "    return mean_squared_error(y_val, preds)\n",
        "\n",
        "# Run Optuna optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=30)\n",
        "print(\"Best Parameters from Optuna:\", study.best_params)\n",
        "\n",
        "# Train final model on train + validation sets\n",
        "X_train_combined = pd.concat([X_train_full, X_val])\n",
        "y_train_combined = pd.concat([y_train_full, y_val])\n",
        "\n",
        "best_params = study.best_params\n",
        "final_model = MultiOutputRegressor(XGBRegressor(**best_params, random_state=42))\n",
        "final_model.fit(X_train_combined, y_train_combined)\n",
        "\n",
        "# Evaluate on test set\n",
        "predictions = final_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"\\nTest MSE: {mse:.4f}\")\n",
        "print(f\"Test RMSE: {rmse:.4f}\")\n",
        "\n",
        "# Predict on a new sample (optional)\n",
        "sample_input = pd.DataFrame([[300,0.25,512, 45, 60]], columns=['latency_ms', 'cpu_allocated', 'memory_allocated', 'cpu_usage_pct', 'memory_usage_pct'])\n",
        "predicted_allocation = final_model.predict(sample_input)\n",
        "print(f\"\\nSample Input Prediction (CPU, Memory): {predicted_allocation[0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Service 2"
      ],
      "metadata": {
        "id": "28Tn0oXt5uwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import optuna\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"Service2.csv\")\n",
        "\n",
        "# Define input features and output targets\n",
        "X = df[['latency_ms', 'cpu_usage_pct', 'memory_usage_pct']]\n",
        "y = df[['cpu_allocated', 'memory_allocated']]\n",
        "\n",
        "# Split into train (70%), validation (15%), test (15%)\n",
        "X_train_full, X_temp, y_train_full, y_temp = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42)\n",
        "\n",
        "print(f\"Train set size: {len(X_train_full)}\")\n",
        "print(f\"Validation set size: {len(X_val)}\")\n",
        "print(f\"Test set size: {len(X_test)}\")\n",
        "\n",
        "# Define Optuna objective function\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
        "    }\n",
        "    model = MultiOutputRegressor(XGBRegressor(**params, random_state=42, verbosity=0))\n",
        "    model.fit(X_train_full, y_train_full)\n",
        "    preds = model.predict(X_val)\n",
        "    return mean_squared_error(y_val, preds)\n",
        "\n",
        "# Run Optuna optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=30)\n",
        "print(\"Best Parameters from Optuna:\", study.best_params)\n",
        "\n",
        "# Train final model on train + validation sets\n",
        "X_train_combined = pd.concat([X_train_full, X_val])\n",
        "y_train_combined = pd.concat([y_train_full, y_val])\n",
        "\n",
        "best_params = study.best_params\n",
        "final_model = MultiOutputRegressor(XGBRegressor(**best_params, random_state=42))\n",
        "final_model.fit(X_train_combined, y_train_combined)\n",
        "\n",
        "# Evaluate on test set\n",
        "predictions = final_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"\\nTest MSE: {mse:.4f}\")\n",
        "print(f\"Test RMSE: {rmse:.4f}\")\n",
        "\n",
        "# Predict on a new sample (optional)\n",
        "sample_input = pd.DataFrame([[300, 45, 60]], columns=['latency_ms', 'cpu_usage_pct', 'memory_usage_pct'])\n",
        "predicted_allocation = final_model.predict(sample_input)\n",
        "print(f\"\\nSample Input Prediction (CPU, Memory): {predicted_allocation[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XP57zz55ws6",
        "outputId": "ea72aeaf-8102-4e41-c1d2-8f942cca8177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-05 05:24:43,111] A new study created in memory with name: no-name-cf26ff66-f736-48b1-a169-c2fc3ef662d1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 7000\n",
            "Validation set size: 1500\n",
            "Test set size: 1500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-05 05:24:43,484] Trial 0 finished with value: 2.0155270099639893 and parameters: {'n_estimators': 121, 'max_depth': 7, 'learning_rate': 0.07740689028917813, 'subsample': 0.8716743342777701, 'colsample_bytree': 0.9326504347162105}. Best is trial 0 with value: 2.0155270099639893.\n",
            "[I 2025-05-05 05:24:45,913] Trial 1 finished with value: 2.04429292678833 and parameters: {'n_estimators': 497, 'max_depth': 5, 'learning_rate': 0.20266540225439258, 'subsample': 0.8759929807528308, 'colsample_bytree': 0.7581415564546611}. Best is trial 0 with value: 2.0155270099639893.\n",
            "[I 2025-05-05 05:24:46,352] Trial 2 finished with value: 2.271047592163086 and parameters: {'n_estimators': 167, 'max_depth': 5, 'learning_rate': 0.047323676140146154, 'subsample': 0.8273863448785178, 'colsample_bytree': 0.7644331224878637}. Best is trial 0 with value: 2.0155270099639893.\n",
            "[I 2025-05-05 05:24:46,651] Trial 3 finished with value: 1.9297618865966797 and parameters: {'n_estimators': 177, 'max_depth': 5, 'learning_rate': 0.10627080098805589, 'subsample': 0.9673735927079299, 'colsample_bytree': 0.8498036861647124}. Best is trial 3 with value: 1.9297618865966797.\n",
            "[I 2025-05-05 05:24:47,010] Trial 4 finished with value: 2.1997570991516113 and parameters: {'n_estimators': 151, 'max_depth': 7, 'learning_rate': 0.18148413247410894, 'subsample': 0.7112655665615122, 'colsample_bytree': 0.8277994399064343}. Best is trial 3 with value: 1.9297618865966797.\n",
            "[I 2025-05-05 05:24:47,227] Trial 5 finished with value: 7.1259355545043945 and parameters: {'n_estimators': 205, 'max_depth': 3, 'learning_rate': 0.1892877747691246, 'subsample': 0.703938143957702, 'colsample_bytree': 0.8333303851763383}. Best is trial 3 with value: 1.9297618865966797.\n",
            "[I 2025-05-05 05:24:47,970] Trial 6 finished with value: 2.230966329574585 and parameters: {'n_estimators': 383, 'max_depth': 7, 'learning_rate': 0.2433671068973838, 'subsample': 0.8583512271852541, 'colsample_bytree': 0.7019413939439794}. Best is trial 3 with value: 1.9297618865966797.\n",
            "[I 2025-05-05 05:24:48,301] Trial 7 finished with value: 2.038940906524658 and parameters: {'n_estimators': 146, 'max_depth': 8, 'learning_rate': 0.2104777347489103, 'subsample': 0.9771494195523414, 'colsample_bytree': 0.7701285806049392}. Best is trial 3 with value: 1.9297618865966797.\n",
            "[I 2025-05-05 05:24:49,133] Trial 8 finished with value: 2.071445941925049 and parameters: {'n_estimators': 495, 'max_depth': 7, 'learning_rate': 0.13451761989088543, 'subsample': 0.9484179592219406, 'colsample_bytree': 0.7233775094506192}. Best is trial 3 with value: 1.9297618865966797.\n",
            "[I 2025-05-05 05:24:49,637] Trial 9 finished with value: 1.8661937713623047 and parameters: {'n_estimators': 190, 'max_depth': 7, 'learning_rate': 0.0502284969771552, 'subsample': 0.9369804852574898, 'colsample_bytree': 0.7267131950749327}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:50,653] Trial 10 finished with value: 2.834636688232422 and parameters: {'n_estimators': 267, 'max_depth': 10, 'learning_rate': 0.022502610961209986, 'subsample': 0.7845980599263098, 'colsample_bytree': 0.9941096464814912}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:51,071] Trial 11 finished with value: 1.963578224182129 and parameters: {'n_estimators': 260, 'max_depth': 5, 'learning_rate': 0.11211128972502588, 'subsample': 0.933236773995159, 'colsample_bytree': 0.8974940260317159}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:51,405] Trial 12 finished with value: 4.036984443664551 and parameters: {'n_estimators': 347, 'max_depth': 3, 'learning_rate': 0.08368305894119447, 'subsample': 0.992317895006827, 'colsample_bytree': 0.8934226515706005}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:52,013] Trial 13 finished with value: 2.4505910873413086 and parameters: {'n_estimators': 212, 'max_depth': 9, 'learning_rate': 0.29720395859500676, 'subsample': 0.9310424888380161, 'colsample_bytree': 0.7946049357683136}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:52,444] Trial 14 finished with value: 784.3710327148438 and parameters: {'n_estimators': 229, 'max_depth': 5, 'learning_rate': 0.011261679484544748, 'subsample': 0.9034646725136037, 'colsample_bytree': 0.8798273400538315}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:52,836] Trial 15 finished with value: 2.2294039726257324 and parameters: {'n_estimators': 322, 'max_depth': 4, 'learning_rate': 0.08372543020230883, 'subsample': 0.9644695427685639, 'colsample_bytree': 0.9610838926703206}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:53,218] Trial 16 finished with value: 1.9966795444488525 and parameters: {'n_estimators': 186, 'max_depth': 6, 'learning_rate': 0.14548006784297252, 'subsample': 0.9116646726213311, 'colsample_bytree': 0.8142647544969156}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:53,500] Trial 17 finished with value: 4.046189308166504 and parameters: {'n_estimators': 106, 'max_depth': 6, 'learning_rate': 0.05259430605219589, 'subsample': 0.8234721760182736, 'colsample_bytree': 0.8681725604604295}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:54,277] Trial 18 finished with value: 1.9619226455688477 and parameters: {'n_estimators': 420, 'max_depth': 8, 'learning_rate': 0.11917949190520499, 'subsample': 0.9996226811569263, 'colsample_bytree': 0.7351039170125365}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:54,635] Trial 19 finished with value: 2.1035261154174805 and parameters: {'n_estimators': 258, 'max_depth': 4, 'learning_rate': 0.05508453795071104, 'subsample': 0.8984826867286573, 'colsample_bytree': 0.9233308428034241}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:55,322] Trial 20 finished with value: 1.9354690313339233 and parameters: {'n_estimators': 293, 'max_depth': 8, 'learning_rate': 0.10718327653236695, 'subsample': 0.9598252829502124, 'colsample_bytree': 0.7944522501993376}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:56,014] Trial 21 finished with value: 1.9211913347244263 and parameters: {'n_estimators': 298, 'max_depth': 8, 'learning_rate': 0.10653929008644386, 'subsample': 0.9553311798521095, 'colsample_bytree': 0.7975741564683578}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:58,319] Trial 22 finished with value: 2.1019744873046875 and parameters: {'n_estimators': 225, 'max_depth': 9, 'learning_rate': 0.15551341095508892, 'subsample': 0.9297240155849269, 'colsample_bytree': 0.8438029336336812}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:59,226] Trial 23 finished with value: 1.8283412456512451 and parameters: {'n_estimators': 426, 'max_depth': 6, 'learning_rate': 0.09581309260021703, 'subsample': 0.9697480435651104, 'colsample_bytree': 0.8028536012869056}. Best is trial 23 with value: 1.8283412456512451.\n",
            "[I 2025-05-05 05:25:00,576] Trial 24 finished with value: 1.8100266456604004 and parameters: {'n_estimators': 441, 'max_depth': 9, 'learning_rate': 0.03783641557069581, 'subsample': 0.9486357483425217, 'colsample_bytree': 0.7997289985809171}. Best is trial 24 with value: 1.8100266456604004.\n",
            "[I 2025-05-05 05:25:02,357] Trial 25 finished with value: 1.8535070419311523 and parameters: {'n_estimators': 451, 'max_depth': 10, 'learning_rate': 0.032402463514997204, 'subsample': 0.8966194090904139, 'colsample_bytree': 0.7386343548392068}. Best is trial 24 with value: 1.8100266456604004.\n",
            "[I 2025-05-05 05:25:04,076] Trial 26 finished with value: 1.9191536903381348 and parameters: {'n_estimators': 444, 'max_depth': 10, 'learning_rate': 0.03718129027073241, 'subsample': 0.8884016364212578, 'colsample_bytree': 0.7520015264671012}. Best is trial 24 with value: 1.8100266456604004.\n",
            "[I 2025-05-05 05:25:05,604] Trial 27 finished with value: 2.0226874351501465 and parameters: {'n_estimators': 452, 'max_depth': 9, 'learning_rate': 0.0719026346912178, 'subsample': 0.7528695809420096, 'colsample_bytree': 0.7819632735093102}. Best is trial 24 with value: 1.8100266456604004.\n",
            "[I 2025-05-05 05:25:07,314] Trial 28 finished with value: 1.8201470375061035 and parameters: {'n_estimators': 386, 'max_depth': 10, 'learning_rate': 0.02456628742943079, 'subsample': 0.8464620809994263, 'colsample_bytree': 0.8161243844216475}. Best is trial 24 with value: 1.8100266456604004.\n",
            "[I 2025-05-05 05:25:08,613] Trial 29 finished with value: 1.9797942638397217 and parameters: {'n_estimators': 389, 'max_depth': 9, 'learning_rate': 0.06699442256935617, 'subsample': 0.8402688459376753, 'colsample_bytree': 0.8202635787914317}. Best is trial 24 with value: 1.8100266456604004.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters from Optuna: {'n_estimators': 441, 'max_depth': 9, 'learning_rate': 0.03783641557069581, 'subsample': 0.9486357483425217, 'colsample_bytree': 0.7997289985809171}\n",
            "\n",
            "Test MSE: 1.7450\n",
            "Test RMSE: 1.3210\n",
            "\n",
            "Sample Input Prediction (CPU, Memory): [4.1809377e-01 8.0070978e+02]\n"
          ]
        }
      ]
    }
  ]
}