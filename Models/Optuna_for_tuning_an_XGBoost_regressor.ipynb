{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB2K61bb42KD",
        "outputId": "a383a98e-bb2f-422d-8fba-4c7c3961f8ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.1)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Service 1"
      ],
      "metadata": {
        "id": "dvnTcx5Y5rOR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12LelU6A4TaB",
        "outputId": "ea1018f3-f6c4-4131-fd7c-d10fe7682f7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-05 05:23:21,528] A new study created in memory with name: no-name-5df2a79e-6a9a-48ba-b799-199d46aa384d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 7000\n",
            "Validation set size: 1500\n",
            "Test set size: 1500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-05 05:23:22,121] Trial 0 finished with value: 2.087468385696411 and parameters: {'n_estimators': 355, 'max_depth': 6, 'learning_rate': 0.1635596850344956, 'subsample': 0.8805197219086345, 'colsample_bytree': 0.9769853631716527}. Best is trial 0 with value: 2.087468385696411.\n",
            "[I 2025-05-05 05:23:22,651] Trial 1 finished with value: 2.1974427700042725 and parameters: {'n_estimators': 328, 'max_depth': 5, 'learning_rate': 0.18748230776050948, 'subsample': 0.8580518973274707, 'colsample_bytree': 0.7398697191367485}. Best is trial 0 with value: 2.087468385696411.\n",
            "[I 2025-05-05 05:23:23,010] Trial 2 finished with value: 2.0826940536499023 and parameters: {'n_estimators': 140, 'max_depth': 7, 'learning_rate': 0.059244198289769665, 'subsample': 0.700841388706234, 'colsample_bytree': 0.9195600232404929}. Best is trial 2 with value: 2.0826940536499023.\n",
            "[I 2025-05-05 05:23:23,375] Trial 3 finished with value: 2.7727108001708984 and parameters: {'n_estimators': 430, 'max_depth': 3, 'learning_rate': 0.20655339151247318, 'subsample': 0.9959451601856675, 'colsample_bytree': 0.9481848698379738}. Best is trial 2 with value: 2.0826940536499023.\n",
            "[I 2025-05-05 05:23:23,768] Trial 4 finished with value: 3.9534337520599365 and parameters: {'n_estimators': 394, 'max_depth': 3, 'learning_rate': 0.07309204665097593, 'subsample': 0.7854953335827789, 'colsample_bytree': 0.9068370261048331}. Best is trial 2 with value: 2.0826940536499023.\n",
            "[I 2025-05-05 05:23:24,544] Trial 5 finished with value: 2.16131329536438 and parameters: {'n_estimators': 197, 'max_depth': 10, 'learning_rate': 0.10950242532303585, 'subsample': 0.8627262330450907, 'colsample_bytree': 0.86066686626125}. Best is trial 2 with value: 2.0826940536499023.\n",
            "[I 2025-05-05 05:23:25,781] Trial 6 finished with value: 2.5162458419799805 and parameters: {'n_estimators': 430, 'max_depth': 9, 'learning_rate': 0.18745592664605076, 'subsample': 0.8394270595064461, 'colsample_bytree': 0.8668698593039517}. Best is trial 2 with value: 2.0826940536499023.\n",
            "[I 2025-05-05 05:23:26,613] Trial 7 finished with value: 2.267171621322632 and parameters: {'n_estimators': 481, 'max_depth': 7, 'learning_rate': 0.19703562960581048, 'subsample': 0.9057585871537228, 'colsample_bytree': 0.8838103859038171}. Best is trial 2 with value: 2.0826940536499023.\n",
            "[I 2025-05-05 05:23:26,874] Trial 8 finished with value: 5.961117744445801 and parameters: {'n_estimators': 231, 'max_depth': 3, 'learning_rate': 0.11007805491416549, 'subsample': 0.7052640130664561, 'colsample_bytree': 0.8073003920751282}. Best is trial 2 with value: 2.0826940536499023.\n",
            "[I 2025-05-05 05:23:27,389] Trial 9 finished with value: 2.230923652648926 and parameters: {'n_estimators': 186, 'max_depth': 8, 'learning_rate': 0.20130310945440494, 'subsample': 0.8031333222422572, 'colsample_bytree': 0.9769144394761264}. Best is trial 2 with value: 2.0826940536499023.\n",
            "[I 2025-05-05 05:23:27,631] Trial 10 finished with value: 7098.6337890625 and parameters: {'n_estimators': 110, 'max_depth': 5, 'learning_rate': 0.01337246676087598, 'subsample': 0.7008303129180333, 'colsample_bytree': 0.7848668846257805}. Best is trial 2 with value: 2.0826940536499023.\n",
            "[I 2025-05-05 05:23:28,157] Trial 11 finished with value: 2.2545549869537354 and parameters: {'n_estimators': 323, 'max_depth': 6, 'learning_rate': 0.2686323781885863, 'subsample': 0.9363768697202615, 'colsample_bytree': 0.9983960720555259}. Best is trial 2 with value: 2.0826940536499023.\n",
            "[I 2025-05-05 05:23:28,811] Trial 12 finished with value: 43.26082992553711 and parameters: {'n_estimators': 261, 'max_depth': 7, 'learning_rate': 0.015567702416865066, 'subsample': 0.7714183151166776, 'colsample_bytree': 0.9317787946245407}. Best is trial 2 with value: 2.0826940536499023.\n",
            "[I 2025-05-05 05:23:29,039] Trial 13 finished with value: 2.335304021835327 and parameters: {'n_estimators': 116, 'max_depth': 5, 'learning_rate': 0.11002438238838347, 'subsample': 0.9323771861566629, 'colsample_bytree': 0.9470270582144913}. Best is trial 2 with value: 2.0826940536499023.\n",
            "[I 2025-05-05 05:23:29,714] Trial 14 finished with value: 1.8638423681259155 and parameters: {'n_estimators': 356, 'max_depth': 6, 'learning_rate': 0.06501163826011067, 'subsample': 0.7488447516783117, 'colsample_bytree': 0.9121860467272286}. Best is trial 14 with value: 1.8638423681259155.\n",
            "[I 2025-05-05 05:23:30,266] Trial 15 finished with value: 1.8839257955551147 and parameters: {'n_estimators': 163, 'max_depth': 8, 'learning_rate': 0.06074728375997958, 'subsample': 0.7425378517920483, 'colsample_bytree': 0.8191085167284914}. Best is trial 14 with value: 1.8638423681259155.\n",
            "[I 2025-05-05 05:23:33,246] Trial 16 finished with value: 1.934944748878479 and parameters: {'n_estimators': 267, 'max_depth': 9, 'learning_rate': 0.057427019730442695, 'subsample': 0.7445412784567346, 'colsample_bytree': 0.8235219071658127}. Best is trial 14 with value: 1.8638423681259155.\n",
            "[I 2025-05-05 05:23:34,070] Trial 17 finished with value: 1.983849048614502 and parameters: {'n_estimators': 285, 'max_depth': 8, 'learning_rate': 0.08759923557671637, 'subsample': 0.7471702101541453, 'colsample_bytree': 0.7628323281813446}. Best is trial 14 with value: 1.8638423681259155.\n",
            "[I 2025-05-05 05:23:34,653] Trial 18 finished with value: 2.0870442390441895 and parameters: {'n_estimators': 195, 'max_depth': 8, 'learning_rate': 0.1380150336656002, 'subsample': 0.80260894009296, 'colsample_bytree': 0.7018978140124332}. Best is trial 14 with value: 1.8638423681259155.\n",
            "[I 2025-05-05 05:23:35,165] Trial 19 finished with value: 2.0279908180236816 and parameters: {'n_estimators': 365, 'max_depth': 4, 'learning_rate': 0.03358661877341353, 'subsample': 0.7405284577722043, 'colsample_bytree': 0.8181931418959615}. Best is trial 14 with value: 1.8638423681259155.\n",
            "[I 2025-05-05 05:23:36,937] Trial 20 finished with value: 2.7430591583251953 and parameters: {'n_estimators': 499, 'max_depth': 10, 'learning_rate': 0.296740600953665, 'subsample': 0.8237619958519335, 'colsample_bytree': 0.8374763370576743}. Best is trial 14 with value: 1.8638423681259155.\n",
            "[I 2025-05-05 05:23:37,842] Trial 21 finished with value: 1.9357185363769531 and parameters: {'n_estimators': 238, 'max_depth': 9, 'learning_rate': 0.03971239809833474, 'subsample': 0.7461008549679775, 'colsample_bytree': 0.829065800607105}. Best is trial 14 with value: 1.8638423681259155.\n",
            "[I 2025-05-05 05:23:38,921] Trial 22 finished with value: 1.923232913017273 and parameters: {'n_estimators': 297, 'max_depth': 9, 'learning_rate': 0.05283155967660663, 'subsample': 0.7309805066427854, 'colsample_bytree': 0.8872337650326515}. Best is trial 14 with value: 1.8638423681259155.\n",
            "[I 2025-05-05 05:23:39,466] Trial 23 finished with value: 1.988732933998108 and parameters: {'n_estimators': 155, 'max_depth': 8, 'learning_rate': 0.08687117408088917, 'subsample': 0.7667960564541131, 'colsample_bytree': 0.8861198764739863}. Best is trial 14 with value: 1.8638423681259155.\n",
            "[I 2025-05-05 05:23:40,584] Trial 24 finished with value: 1.9129606485366821 and parameters: {'n_estimators': 308, 'max_depth': 9, 'learning_rate': 0.046526297581821266, 'subsample': 0.7256756454335295, 'colsample_bytree': 0.8783433445557984}. Best is trial 14 with value: 1.8638423681259155.\n",
            "[I 2025-05-05 05:23:41,317] Trial 25 finished with value: 2.0449061393737793 and parameters: {'n_estimators': 378, 'max_depth': 6, 'learning_rate': 0.12915432901774734, 'subsample': 0.7203528216941126, 'colsample_bytree': 0.8520367433007637}. Best is trial 14 with value: 1.8638423681259155.\n",
            "[I 2025-05-05 05:23:42,151] Trial 26 finished with value: 1.905738115310669 and parameters: {'n_estimators': 328, 'max_depth': 7, 'learning_rate': 0.03182947123451506, 'subsample': 0.7672669424799473, 'colsample_bytree': 0.7951102282973803}. Best is trial 14 with value: 1.8638423681259155.\n",
            "[I 2025-05-05 05:23:43,105] Trial 27 finished with value: 1.9442167282104492 and parameters: {'n_estimators': 414, 'max_depth': 7, 'learning_rate': 0.07852918193588629, 'subsample': 0.7959661635135871, 'colsample_bytree': 0.7858128997246571}. Best is trial 14 with value: 1.8638423681259155.\n",
            "[I 2025-05-05 05:23:45,522] Trial 28 finished with value: 2.128445863723755 and parameters: {'n_estimators': 338, 'max_depth': 6, 'learning_rate': 0.02427784301416122, 'subsample': 0.7743122010649172, 'colsample_bytree': 0.7938229532145891}. Best is trial 14 with value: 1.8638423681259155.\n",
            "[I 2025-05-05 05:23:46,397] Trial 29 finished with value: 2.049520492553711 and parameters: {'n_estimators': 351, 'max_depth': 6, 'learning_rate': 0.16151700188060264, 'subsample': 0.8160092593106054, 'colsample_bytree': 0.7152834115422863}. Best is trial 14 with value: 1.8638423681259155.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters from Optuna: {'n_estimators': 356, 'max_depth': 6, 'learning_rate': 0.06501163826011067, 'subsample': 0.7488447516783117, 'colsample_bytree': 0.9121860467272286}\n",
            "\n",
            "Test MSE: 1.6407\n",
            "Test RMSE: 1.2809\n",
            "\n",
            "Sample Input Prediction (CPU, Memory): [3.955172e-01 8.311766e+02]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import optuna\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"Service1.csv\")\n",
        "\n",
        "# Define input features and output targets\n",
        "X = df[['latency_ms', 'cpu_usage_pct', 'memory_usage_pct']]\n",
        "y = df[['cpu_allocated', 'memory_allocated']]\n",
        "\n",
        "# Split into train (70%), validation (15%), test (15%)\n",
        "X_train_full, X_temp, y_train_full, y_temp = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42)\n",
        "\n",
        "print(f\"Train set size: {len(X_train_full)}\")\n",
        "print(f\"Validation set size: {len(X_val)}\")\n",
        "print(f\"Test set size: {len(X_test)}\")\n",
        "\n",
        "# Define Optuna objective function\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
        "    }\n",
        "    model = MultiOutputRegressor(XGBRegressor(**params, random_state=42, verbosity=0))\n",
        "    model.fit(X_train_full, y_train_full)\n",
        "    preds = model.predict(X_val)\n",
        "    return mean_squared_error(y_val, preds)\n",
        "\n",
        "# Run Optuna optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=30)\n",
        "print(\"Best Parameters from Optuna:\", study.best_params)\n",
        "\n",
        "# Train final model on train + validation sets\n",
        "X_train_combined = pd.concat([X_train_full, X_val])\n",
        "y_train_combined = pd.concat([y_train_full, y_val])\n",
        "\n",
        "best_params = study.best_params\n",
        "final_model = MultiOutputRegressor(XGBRegressor(**best_params, random_state=42))\n",
        "final_model.fit(X_train_combined, y_train_combined)\n",
        "\n",
        "# Evaluate on test set\n",
        "predictions = final_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"\\nTest MSE: {mse:.4f}\")\n",
        "print(f\"Test RMSE: {rmse:.4f}\")\n",
        "\n",
        "# Predict on a new sample (optional)\n",
        "sample_input = pd.DataFrame([[300, 45, 60]], columns=['latency_ms', 'cpu_usage_pct', 'memory_usage_pct'])\n",
        "predicted_allocation = final_model.predict(sample_input)\n",
        "print(f\"\\nSample Input Prediction (CPU, Memory): {predicted_allocation[0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Service 2"
      ],
      "metadata": {
        "id": "28Tn0oXt5uwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import optuna\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"Service2.csv\")\n",
        "\n",
        "# Define input features and output targets\n",
        "X = df[['latency_ms', 'cpu_usage_pct', 'memory_usage_pct']]\n",
        "y = df[['cpu_allocated', 'memory_allocated']]\n",
        "\n",
        "# Split into train (70%), validation (15%), test (15%)\n",
        "X_train_full, X_temp, y_train_full, y_temp = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42)\n",
        "\n",
        "print(f\"Train set size: {len(X_train_full)}\")\n",
        "print(f\"Validation set size: {len(X_val)}\")\n",
        "print(f\"Test set size: {len(X_test)}\")\n",
        "\n",
        "# Define Optuna objective function\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
        "    }\n",
        "    model = MultiOutputRegressor(XGBRegressor(**params, random_state=42, verbosity=0))\n",
        "    model.fit(X_train_full, y_train_full)\n",
        "    preds = model.predict(X_val)\n",
        "    return mean_squared_error(y_val, preds)\n",
        "\n",
        "# Run Optuna optimization\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=30)\n",
        "print(\"Best Parameters from Optuna:\", study.best_params)\n",
        "\n",
        "# Train final model on train + validation sets\n",
        "X_train_combined = pd.concat([X_train_full, X_val])\n",
        "y_train_combined = pd.concat([y_train_full, y_val])\n",
        "\n",
        "best_params = study.best_params\n",
        "final_model = MultiOutputRegressor(XGBRegressor(**best_params, random_state=42))\n",
        "final_model.fit(X_train_combined, y_train_combined)\n",
        "\n",
        "# Evaluate on test set\n",
        "predictions = final_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f\"\\nTest MSE: {mse:.4f}\")\n",
        "print(f\"Test RMSE: {rmse:.4f}\")\n",
        "\n",
        "# Predict on a new sample (optional)\n",
        "sample_input = pd.DataFrame([[300, 45, 60]], columns=['latency_ms', 'cpu_usage_pct', 'memory_usage_pct'])\n",
        "predicted_allocation = final_model.predict(sample_input)\n",
        "print(f\"\\nSample Input Prediction (CPU, Memory): {predicted_allocation[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XP57zz55ws6",
        "outputId": "ea72aeaf-8102-4e41-c1d2-8f942cca8177"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-05 05:24:43,111] A new study created in memory with name: no-name-cf26ff66-f736-48b1-a169-c2fc3ef662d1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 7000\n",
            "Validation set size: 1500\n",
            "Test set size: 1500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-05 05:24:43,484] Trial 0 finished with value: 2.0155270099639893 and parameters: {'n_estimators': 121, 'max_depth': 7, 'learning_rate': 0.07740689028917813, 'subsample': 0.8716743342777701, 'colsample_bytree': 0.9326504347162105}. Best is trial 0 with value: 2.0155270099639893.\n",
            "[I 2025-05-05 05:24:45,913] Trial 1 finished with value: 2.04429292678833 and parameters: {'n_estimators': 497, 'max_depth': 5, 'learning_rate': 0.20266540225439258, 'subsample': 0.8759929807528308, 'colsample_bytree': 0.7581415564546611}. Best is trial 0 with value: 2.0155270099639893.\n",
            "[I 2025-05-05 05:24:46,352] Trial 2 finished with value: 2.271047592163086 and parameters: {'n_estimators': 167, 'max_depth': 5, 'learning_rate': 0.047323676140146154, 'subsample': 0.8273863448785178, 'colsample_bytree': 0.7644331224878637}. Best is trial 0 with value: 2.0155270099639893.\n",
            "[I 2025-05-05 05:24:46,651] Trial 3 finished with value: 1.9297618865966797 and parameters: {'n_estimators': 177, 'max_depth': 5, 'learning_rate': 0.10627080098805589, 'subsample': 0.9673735927079299, 'colsample_bytree': 0.8498036861647124}. Best is trial 3 with value: 1.9297618865966797.\n",
            "[I 2025-05-05 05:24:47,010] Trial 4 finished with value: 2.1997570991516113 and parameters: {'n_estimators': 151, 'max_depth': 7, 'learning_rate': 0.18148413247410894, 'subsample': 0.7112655665615122, 'colsample_bytree': 0.8277994399064343}. Best is trial 3 with value: 1.9297618865966797.\n",
            "[I 2025-05-05 05:24:47,227] Trial 5 finished with value: 7.1259355545043945 and parameters: {'n_estimators': 205, 'max_depth': 3, 'learning_rate': 0.1892877747691246, 'subsample': 0.703938143957702, 'colsample_bytree': 0.8333303851763383}. Best is trial 3 with value: 1.9297618865966797.\n",
            "[I 2025-05-05 05:24:47,970] Trial 6 finished with value: 2.230966329574585 and parameters: {'n_estimators': 383, 'max_depth': 7, 'learning_rate': 0.2433671068973838, 'subsample': 0.8583512271852541, 'colsample_bytree': 0.7019413939439794}. Best is trial 3 with value: 1.9297618865966797.\n",
            "[I 2025-05-05 05:24:48,301] Trial 7 finished with value: 2.038940906524658 and parameters: {'n_estimators': 146, 'max_depth': 8, 'learning_rate': 0.2104777347489103, 'subsample': 0.9771494195523414, 'colsample_bytree': 0.7701285806049392}. Best is trial 3 with value: 1.9297618865966797.\n",
            "[I 2025-05-05 05:24:49,133] Trial 8 finished with value: 2.071445941925049 and parameters: {'n_estimators': 495, 'max_depth': 7, 'learning_rate': 0.13451761989088543, 'subsample': 0.9484179592219406, 'colsample_bytree': 0.7233775094506192}. Best is trial 3 with value: 1.9297618865966797.\n",
            "[I 2025-05-05 05:24:49,637] Trial 9 finished with value: 1.8661937713623047 and parameters: {'n_estimators': 190, 'max_depth': 7, 'learning_rate': 0.0502284969771552, 'subsample': 0.9369804852574898, 'colsample_bytree': 0.7267131950749327}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:50,653] Trial 10 finished with value: 2.834636688232422 and parameters: {'n_estimators': 267, 'max_depth': 10, 'learning_rate': 0.022502610961209986, 'subsample': 0.7845980599263098, 'colsample_bytree': 0.9941096464814912}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:51,071] Trial 11 finished with value: 1.963578224182129 and parameters: {'n_estimators': 260, 'max_depth': 5, 'learning_rate': 0.11211128972502588, 'subsample': 0.933236773995159, 'colsample_bytree': 0.8974940260317159}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:51,405] Trial 12 finished with value: 4.036984443664551 and parameters: {'n_estimators': 347, 'max_depth': 3, 'learning_rate': 0.08368305894119447, 'subsample': 0.992317895006827, 'colsample_bytree': 0.8934226515706005}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:52,013] Trial 13 finished with value: 2.4505910873413086 and parameters: {'n_estimators': 212, 'max_depth': 9, 'learning_rate': 0.29720395859500676, 'subsample': 0.9310424888380161, 'colsample_bytree': 0.7946049357683136}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:52,444] Trial 14 finished with value: 784.3710327148438 and parameters: {'n_estimators': 229, 'max_depth': 5, 'learning_rate': 0.011261679484544748, 'subsample': 0.9034646725136037, 'colsample_bytree': 0.8798273400538315}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:52,836] Trial 15 finished with value: 2.2294039726257324 and parameters: {'n_estimators': 322, 'max_depth': 4, 'learning_rate': 0.08372543020230883, 'subsample': 0.9644695427685639, 'colsample_bytree': 0.9610838926703206}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:53,218] Trial 16 finished with value: 1.9966795444488525 and parameters: {'n_estimators': 186, 'max_depth': 6, 'learning_rate': 0.14548006784297252, 'subsample': 0.9116646726213311, 'colsample_bytree': 0.8142647544969156}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:53,500] Trial 17 finished with value: 4.046189308166504 and parameters: {'n_estimators': 106, 'max_depth': 6, 'learning_rate': 0.05259430605219589, 'subsample': 0.8234721760182736, 'colsample_bytree': 0.8681725604604295}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:54,277] Trial 18 finished with value: 1.9619226455688477 and parameters: {'n_estimators': 420, 'max_depth': 8, 'learning_rate': 0.11917949190520499, 'subsample': 0.9996226811569263, 'colsample_bytree': 0.7351039170125365}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:54,635] Trial 19 finished with value: 2.1035261154174805 and parameters: {'n_estimators': 258, 'max_depth': 4, 'learning_rate': 0.05508453795071104, 'subsample': 0.8984826867286573, 'colsample_bytree': 0.9233308428034241}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:55,322] Trial 20 finished with value: 1.9354690313339233 and parameters: {'n_estimators': 293, 'max_depth': 8, 'learning_rate': 0.10718327653236695, 'subsample': 0.9598252829502124, 'colsample_bytree': 0.7944522501993376}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:56,014] Trial 21 finished with value: 1.9211913347244263 and parameters: {'n_estimators': 298, 'max_depth': 8, 'learning_rate': 0.10653929008644386, 'subsample': 0.9553311798521095, 'colsample_bytree': 0.7975741564683578}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:58,319] Trial 22 finished with value: 2.1019744873046875 and parameters: {'n_estimators': 225, 'max_depth': 9, 'learning_rate': 0.15551341095508892, 'subsample': 0.9297240155849269, 'colsample_bytree': 0.8438029336336812}. Best is trial 9 with value: 1.8661937713623047.\n",
            "[I 2025-05-05 05:24:59,226] Trial 23 finished with value: 1.8283412456512451 and parameters: {'n_estimators': 426, 'max_depth': 6, 'learning_rate': 0.09581309260021703, 'subsample': 0.9697480435651104, 'colsample_bytree': 0.8028536012869056}. Best is trial 23 with value: 1.8283412456512451.\n",
            "[I 2025-05-05 05:25:00,576] Trial 24 finished with value: 1.8100266456604004 and parameters: {'n_estimators': 441, 'max_depth': 9, 'learning_rate': 0.03783641557069581, 'subsample': 0.9486357483425217, 'colsample_bytree': 0.7997289985809171}. Best is trial 24 with value: 1.8100266456604004.\n",
            "[I 2025-05-05 05:25:02,357] Trial 25 finished with value: 1.8535070419311523 and parameters: {'n_estimators': 451, 'max_depth': 10, 'learning_rate': 0.032402463514997204, 'subsample': 0.8966194090904139, 'colsample_bytree': 0.7386343548392068}. Best is trial 24 with value: 1.8100266456604004.\n",
            "[I 2025-05-05 05:25:04,076] Trial 26 finished with value: 1.9191536903381348 and parameters: {'n_estimators': 444, 'max_depth': 10, 'learning_rate': 0.03718129027073241, 'subsample': 0.8884016364212578, 'colsample_bytree': 0.7520015264671012}. Best is trial 24 with value: 1.8100266456604004.\n",
            "[I 2025-05-05 05:25:05,604] Trial 27 finished with value: 2.0226874351501465 and parameters: {'n_estimators': 452, 'max_depth': 9, 'learning_rate': 0.0719026346912178, 'subsample': 0.7528695809420096, 'colsample_bytree': 0.7819632735093102}. Best is trial 24 with value: 1.8100266456604004.\n",
            "[I 2025-05-05 05:25:07,314] Trial 28 finished with value: 1.8201470375061035 and parameters: {'n_estimators': 386, 'max_depth': 10, 'learning_rate': 0.02456628742943079, 'subsample': 0.8464620809994263, 'colsample_bytree': 0.8161243844216475}. Best is trial 24 with value: 1.8100266456604004.\n",
            "[I 2025-05-05 05:25:08,613] Trial 29 finished with value: 1.9797942638397217 and parameters: {'n_estimators': 389, 'max_depth': 9, 'learning_rate': 0.06699442256935617, 'subsample': 0.8402688459376753, 'colsample_bytree': 0.8202635787914317}. Best is trial 24 with value: 1.8100266456604004.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters from Optuna: {'n_estimators': 441, 'max_depth': 9, 'learning_rate': 0.03783641557069581, 'subsample': 0.9486357483425217, 'colsample_bytree': 0.7997289985809171}\n",
            "\n",
            "Test MSE: 1.7450\n",
            "Test RMSE: 1.3210\n",
            "\n",
            "Sample Input Prediction (CPU, Memory): [4.1809377e-01 8.0070978e+02]\n"
          ]
        }
      ]
    }
  ]
}